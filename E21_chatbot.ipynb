{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 21-14. 프로젝트: 한국어 데이터로 챗봇 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_file = pd.read_csv('/home/aiffel0042/aiffel/songys_chatbot/ChatbotData .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5285</th>\n",
       "      <td>힘내야지</td>\n",
       "      <td>응원합니다!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5286</th>\n",
       "      <td>힘든 것 좀 끝났으면</td>\n",
       "      <td>다 지나갈 거예요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5287</th>\n",
       "      <td>힘든 시기가 지나갔으면</td>\n",
       "      <td>다 지나갈 거예요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5288</th>\n",
       "      <td>힘든 데도 날 도와준 사람</td>\n",
       "      <td>잊지말고 보답하세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>힘차게 시작</td>\n",
       "      <td>응원합니다!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5290 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Q            A  label\n",
       "0              12시 땡!   하루가 또 가네요.      0\n",
       "1         1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2        3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3     3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4             PPL 심하네   눈살이 찌푸려지죠.      0\n",
       "...               ...          ...    ...\n",
       "5285             힘내야지       응원합니다!      0\n",
       "5286      힘든 것 좀 끝났으면   다 지나갈 거예요.      0\n",
       "5287     힘든 시기가 지나갔으면   다 지나갈 거예요.      0\n",
       "5288   힘든 데도 날 도와준 사람  잊지말고 보답하세요.      0\n",
       "5289           힘차게 시작       응원합니다!      0\n",
       "\n",
       "[5290 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_file[row_file['label']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5290</th>\n",
       "      <td>1000일 만난 여자친구와 이별</td>\n",
       "      <td>더 오래 만날 사람 만날 거예요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5291</th>\n",
       "      <td>10년 연애. 헤어졌습니다.</td>\n",
       "      <td>더 공허함이 크시겠네요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5292</th>\n",
       "      <td>10년 연애사 되돌아보니 다 부질없네</td>\n",
       "      <td>더 좋은 사람 만나실 거예요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5293</th>\n",
       "      <td>10년 연예의끝</td>\n",
       "      <td>더 마음이 허하겠어요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5294</th>\n",
       "      <td>10년만나다 헤어지네</td>\n",
       "      <td>충분히 슬퍼하고 충분히 아파하다가 이겨내세요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6533 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                          A  label\n",
       "5290         1000일 만난 여자친구와 이별         더 오래 만날 사람 만날 거예요.      1\n",
       "5291           10년 연애. 헤어졌습니다.              더 공허함이 크시겠네요.      1\n",
       "5292      10년 연애사 되돌아보니 다 부질없네           더 좋은 사람 만나실 거예요.      1\n",
       "5293                  10년 연예의끝               더 마음이 허하겠어요.      1\n",
       "5294               10년만나다 헤어지네  충분히 슬퍼하고 충분히 아파하다가 이겨내세요.      1\n",
       "...                        ...                        ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.         티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.              훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                     설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?   잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐         도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[6533 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_file[row_file['label']!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 전처리하기\n",
    "영어 데이터와는 전혀 다른 데이터인만큼 영어 데이터에 사용했던 전처리와 일부 동일한 전처리도 필요하겠지만 전체적으로는 다른 전처리를 수행해야 할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "  # (한글, 숫자, 영어 \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r\"[^ㄱ-ㅎ|가-힣|a-z|A-Z|0-9|?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         12시 땡!\n",
       "1                    1지망 학교 떨어졌어\n",
       "2                   3박4일 놀러가고 싶다\n",
       "3                3박4일 정도 놀러가고 싶다\n",
       "4                        PPL 심하네\n",
       "                  ...           \n",
       "11818             훔쳐보는 것도 눈치 보임.\n",
       "11819             훔쳐보는 것도 눈치 보임.\n",
       "11820                흑기사 해주는 짝남.\n",
       "11821    힘든 연애 좋은 연애라는게 무슨 차이일까?\n",
       "11822                 힘들어서 결혼할까봐\n",
       "Name: Q, Length: 11823, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_file['Q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for i in row_file['Q']:\n",
    "    questions.append(preprocess_sentence(i))\n",
    "\n",
    "answers = []\n",
    "for i in row_file['A']:\n",
    "    answers.append(preprocess_sentence(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12시 땡 !',\n",
       " '1지망 학교 떨어졌어',\n",
       " '3박4일 놀러가고 싶다',\n",
       " '3박4일 정도 놀러가고 싶다',\n",
       " 'ppl 심하네',\n",
       " 'sd카드 망가졌어',\n",
       " 'sd카드 안돼',\n",
       " 'sns 맞팔 왜 안하지',\n",
       " 'sns 시간낭비인 거 아는데 매일 하는 중',\n",
       " 'sns 시간낭비인데 자꾸 보게됨',\n",
       " 'sns보면 나만 빼고 다 행복해보여',\n",
       " '가끔 궁금해',\n",
       " '가끔 뭐하는지 궁금해',\n",
       " '가끔은 혼자인게 좋다',\n",
       " '가난한 자의 설움',\n",
       " '가만 있어도 땀난다',\n",
       " '가상화폐 쫄딱 망함',\n",
       " '가스불 켜고 나갔어',\n",
       " '가스불 켜놓고 나온거 같아',\n",
       " '가스비 너무 많이 나왔다 .',\n",
       " '가스비 비싼데 감기 걸리겠어',\n",
       " '가스비 장난 아님',\n",
       " '가장 확실한 건 뭘까 ?',\n",
       " '가족 여행 가기로 했어',\n",
       " '가족 여행 고고',\n",
       " '가족 여행 어디로 가지 ?',\n",
       " '가족 있어 ?',\n",
       " '가족관계 알려 줘',\n",
       " '가족끼리 여행간다 .',\n",
       " '가족들 보고 싶어',\n",
       " '가족들이랑 서먹해',\n",
       " '가족들이랑 서먹해졌어',\n",
       " '가족들이랑 어디 가지 ?',\n",
       " '가족들이랑 여행 갈거야',\n",
       " '가족여행 가야지',\n",
       " '가족이 누구야 ?',\n",
       " '가족이랑 여행 가려고',\n",
       " '가족한테 스트레스 풀었어',\n",
       " '가출할까 ?',\n",
       " '가출해도 갈 데가 없어',\n",
       " '간만에 떨리니까 좋더라',\n",
       " '간만에 쇼핑 중',\n",
       " '간만에 휴식 중',\n",
       " '간식 뭐 먹을까',\n",
       " '간식 추천',\n",
       " '간장치킨 시켜야지',\n",
       " '간접흡연 싫어',\n",
       " '갈까 말까 고민 돼',\n",
       " '갈까 말까 ?',\n",
       " '감 말랭이 먹고 싶다 .',\n",
       " '감 말랭이 먹어야지',\n",
       " '감기 같애',\n",
       " '감기 걸린 것 같아',\n",
       " '감기 기운이 있어',\n",
       " '감기 들 거 같애',\n",
       " '감기가 오려나',\n",
       " '감기약이 없어',\n",
       " '감기인거 같애',\n",
       " '감미로운 목소리 좋아',\n",
       " '감정이 쓰레기통처럼 엉망진창이야',\n",
       " '감정컨트롤을 못하겠어',\n",
       " '감정컨트롤이 안돼',\n",
       " '감히 나를 무시하는 애가 있어',\n",
       " '갑자기 나쁜 생각이 막 들더라',\n",
       " '갑자기 눈물 나',\n",
       " '갑자기 물어봐서 당황했어',\n",
       " '갑자기 불편한 사이가 된 거 같아',\n",
       " '강렬한 첫인상 남겨야 하는데',\n",
       " '강아지 키우고 싶어',\n",
       " '강아지 키우고 싶은데 역시 안돼겠지',\n",
       " '강아지 키울 수 있을까',\n",
       " '강아지 키울까',\n",
       " '강원도 가서 살까 ?',\n",
       " '같이 게임하자고 해도 되나 ?',\n",
       " '같이 놀러갈 친구가 없어',\n",
       " '같이 먹었는데 나만 살찐 거 같아',\n",
       " '같이 수영장 가기로 했어',\n",
       " '같이 있으면 힘든데 붙잡고 싶어',\n",
       " '같이 피씨방 가자고 해볼까 ?',\n",
       " '같이 할 수 있는 취미 생활 뭐 있을까',\n",
       " '개강룩 입어볼까',\n",
       " '개강옷 예쁘게 입어 볼까',\n",
       " '개강이다',\n",
       " '개강이라니',\n",
       " '개같은 상황',\n",
       " '개같이 되버렸어 .',\n",
       " '개기름 꼈어',\n",
       " '개념도 놓고 옴',\n",
       " '개념이 없어',\n",
       " '개당황',\n",
       " '개당황했잖아 갑자기 물어 봐서',\n",
       " '개인적인 업무까지 다 시켜',\n",
       " '개인적인 일도 다 시켜',\n",
       " '개졸려',\n",
       " '개좋아',\n",
       " '개학하니까 좋다',\n",
       " '걔 너무 싫다',\n",
       " '걔는 누굴 닮아서 그런거니 ?',\n",
       " '걔랑 같은 반 됐으면 좋겠다',\n",
       " '거지 같이 일해 놓고 갔어',\n",
       " '거지됐어',\n",
       " '거짓말 했어',\n",
       " '거짓말을 나도 모르게 자꾸 해',\n",
       " '거짓말을 하게 돼',\n",
       " '거짓말이 거짓말을 낳아',\n",
       " '걱정 없이 살고파',\n",
       " '걱정 좀 없이 살고 싶다 .',\n",
       " '건강 관리',\n",
       " '건강 빨리 회복해야지',\n",
       " '건강검진 왔어',\n",
       " '건강검진하러 옴',\n",
       " '건강이 최고',\n",
       " '건강이 최고인 것 같아',\n",
       " '건강하게 다이어트 하는 방법',\n",
       " '건강한 다이어트법',\n",
       " '건너건너 아는 사람인데 연락해도 될까 ?',\n",
       " '건물주 되고싶어',\n",
       " '건물주가 짱인데',\n",
       " '건방져',\n",
       " '건조기 살까봐',\n",
       " '건조하네',\n",
       " '걸레질도 해야 돼',\n",
       " '걸어 가고 있는데 깜깜해서 무서워',\n",
       " '겁난다',\n",
       " '게으른 동료가 있어',\n",
       " '게임 같이 하자고 할까 ?',\n",
       " '게임 때문에 시간 다갔어',\n",
       " '게임 때문에 폰이 점점 느려지는듯',\n",
       " '게임 재미있어 .',\n",
       " '게임 지겨워',\n",
       " '게임도 이제 재미없어',\n",
       " '게임하고 싶어',\n",
       " '게임하다 시간 다갔어',\n",
       " '겨울 지나 봄이야',\n",
       " '겨울에는 온천이지 !',\n",
       " '겨울이 가고 봄이 올거야',\n",
       " '격려 좀 해줘',\n",
       " '격려가 필요해 .',\n",
       " '견과류 챙겨 먹어야지 .',\n",
       " '결국 이런 운명이라니 슬프다',\n",
       " '결정 못하겠어 .',\n",
       " '결정은 빠르면 빠를 수록 좋겠지 ?',\n",
       " '결정은 빠를수록 좋겠지 ?',\n",
       " '결정을 못 내리겠어 . 어떻해',\n",
       " '결정적인 물증이 없어',\n",
       " '결혼 했는데 .',\n",
       " '결혼 했어',\n",
       " '결혼도 다 돈이다 .',\n",
       " '결혼식 가기 귀찮아',\n",
       " '결혼식 또 가야돼',\n",
       " '결혼식때 하객이 없을 까봐 걱정돼',\n",
       " '결혼식이 너무 많아',\n",
       " '결혼이나 하지 왜 자꾸 나한테 화 내냐구 !',\n",
       " '결혼준비 돈 많이 들겠지',\n",
       " '결혼준비하는데 돈 얼마나 드나',\n",
       " '결혼하는데 돈 많이 드네',\n",
       " '결혼하는데 돈 얼마나 들까',\n",
       " '결혼하면 좋아 ?',\n",
       " '결혼하면 좋을까',\n",
       " '결혼하면 행복할까 ?',\n",
       " '결혼하면 행복해 ?',\n",
       " '결혼하면 행복해질까 ?',\n",
       " '결혼할까',\n",
       " '결혼해도 되나',\n",
       " '결혼해도 될까',\n",
       " '결혼해야 하나',\n",
       " '경쟁이 너무 치열해',\n",
       " '계속 공부해도 될까',\n",
       " '계속 도전하는 거 귀찮아',\n",
       " '계속 방학이면 좋을텐데',\n",
       " '계속 보고 싶어',\n",
       " '계속 보고 싶으면 어떡해 ?',\n",
       " '계속 속이 진짜 안 좋아',\n",
       " '계속 엇갈리는 느낌',\n",
       " '계속 학생하고 싶어',\n",
       " '계속 한숨만 나와',\n",
       " '고3은 공부만 해야겠지 .',\n",
       " '고3이니까 공부해야겠지',\n",
       " '고구마 다이어트 해야지',\n",
       " '고구마만 먹고 다이어트 해야지',\n",
       " '고기 구워 먹고 싶다 .',\n",
       " '고기 먹고 싶어',\n",
       " '고데기 망했어',\n",
       " '고데기 했는데 망했어',\n",
       " '고독한 밤',\n",
       " '고마운 사람들이 많아',\n",
       " '고무신 거꾸로 신으면 어쩌지',\n",
       " '고민 있어',\n",
       " '고민 좀 들어줄래',\n",
       " '고백하고 후회하면 어떡하지',\n",
       " '고시원 너무 답답해',\n",
       " '고시원 답답해',\n",
       " '고시원에서 나가고 싶어',\n",
       " '고시원에서 탈출하고 싶어',\n",
       " '고양이 동영상 보는 중',\n",
       " '고양이 키우고 싶어',\n",
       " '고양이 키우고 싶어',\n",
       " '고의는 아닌데 실수를 한 거 같아',\n",
       " '고집 센 사람',\n",
       " '고집하고는',\n",
       " '골프 못 치는데',\n",
       " '골프 배워야 돼',\n",
       " '골프 어려워',\n",
       " '골프치러 가야돼',\n",
       " '곱창 먹고 싶어 .',\n",
       " '곱창 생각나',\n",
       " '공무원 괜찮겠지',\n",
       " '공무원 되고 싶다',\n",
       " '공무원 되면 좋겠다',\n",
       " '공무원 시험 공부 힘들다',\n",
       " '공무원 시험 죽을 거 같아',\n",
       " '공무원 시험 힘들어',\n",
       " '공무원 준비할까',\n",
       " '공무원이 좋지 ?',\n",
       " '공복이라 신경이 예민해져',\n",
       " '공복이라 예민해',\n",
       " '공복이면 예민함 ?',\n",
       " '공부 계속해도 될까',\n",
       " '공부 꼭 해야 할까',\n",
       " '공부 때려치워야 하나',\n",
       " '공부 시작해도 될까',\n",
       " '공부 왜 해야 돼 ?',\n",
       " '공부 잘 안돼',\n",
       " '공부 잘하고 싶어',\n",
       " '공부 좀 더 할 걸',\n",
       " '공부 하기 싫다',\n",
       " '공부는 내 체질이 아닌 것 같아',\n",
       " '공부로 먹고 살 수 있을까',\n",
       " '공부방법이 잘못된걸까 ?',\n",
       " '공부하기 싫어',\n",
       " '공부하기 싫은 날',\n",
       " '공부하는 낙이 없어',\n",
       " '공부하는 이유 ?',\n",
       " '공부하는 이유가 없어',\n",
       " '공시 준비 힘들어',\n",
       " '공시 준비 힘들어',\n",
       " '공시 준비중',\n",
       " '공시 준비하는데 힘들다',\n",
       " '공시생이야',\n",
       " '공연 보고 싶어',\n",
       " '공연 보러 가고 싶어',\n",
       " '공책 필기 나만 힘들어 ?',\n",
       " '공황장애 생겼어 .',\n",
       " '공황장애 있어',\n",
       " '공휴일에는 집이 최고',\n",
       " '공휴일에는 집콕',\n",
       " '과거는 잊고 앞으로 나아 가야지',\n",
       " '과거는 중요하지 않아',\n",
       " '과식해서 소화가 안돼',\n",
       " '과식했나 봐',\n",
       " '과식했다',\n",
       " '과외비 부담되겠지 ?',\n",
       " '과외비 비싸 ?',\n",
       " '과일 먹고 자야지',\n",
       " '과일 먹어야지 .',\n",
       " '과일 안 먹게 돼',\n",
       " '과일 잘 안 먹게 돼',\n",
       " '과일 챙겨 먹어야지',\n",
       " '관계가 계속 애매하다 .',\n",
       " '관심 끄라고 하고 싶다 .',\n",
       " '관심 좀 안 가졌으면',\n",
       " '관절염 같애',\n",
       " '관절염인가',\n",
       " '광고가 안 끝나',\n",
       " '괜찮아지고 있어',\n",
       " '괜찮은 사람인데 사귀긴 싫어',\n",
       " '괜히 건들지 말라고',\n",
       " '괜히 기다렸어',\n",
       " '괜히 농담해서 망했다',\n",
       " '괜히 아까운 시간 버렸다',\n",
       " '괜히 창피해',\n",
       " '괴물이 되어 가는 느낌이 들어',\n",
       " '교보문고 왔어',\n",
       " '교양 수업 재밌어',\n",
       " '교양수업 시간에 마음에 드는 애 있어',\n",
       " '교양수업 은근 재미져',\n",
       " '교양수업에서 마음에 드는 애 있어',\n",
       " '교양수업이 재미있어',\n",
       " '교양이 전공보다 재미있어',\n",
       " '교직이수 가능할까',\n",
       " '교통사고 났었어 .',\n",
       " '교통사고 당했어',\n",
       " '교회 가기 싫어',\n",
       " '교회 갔다 만났어',\n",
       " '교회에서 만났어',\n",
       " '구박하면서 엄청 일 시켜',\n",
       " '군대 갔다 올 때까지 기다릴 수 있을까',\n",
       " '군대 기다려 주려고',\n",
       " '군대 기다려도 될까',\n",
       " '군대 기다리면 부담스러워할까',\n",
       " '군대 기다릴 수 있을까',\n",
       " '군대 언제 끝나나',\n",
       " '군대 전역 기다려',\n",
       " '굿모닝',\n",
       " '궁금하면 오백원',\n",
       " '궁금하지 ?',\n",
       " '궁금해',\n",
       " '궁금해 알려줘',\n",
       " '귀 아파',\n",
       " '귀가 가려워',\n",
       " '귀가 간지러',\n",
       " '귀가 윙윙거려',\n",
       " '귀농 어때 ?',\n",
       " '그 사람이 나 안 좋아하는 거 같아',\n",
       " '그 사람이 나 좋아해줬으면 좋겠다',\n",
       " '그 사람이 행복했으면 좋겠다',\n",
       " '그 시절엔 다 그랬지',\n",
       " '그냥 고백할걸',\n",
       " '그냥 공무원이 좋을 듯',\n",
       " '그냥 내버려 둬 주었으면',\n",
       " '그냥 선 볼까 ?',\n",
       " '그냥 쉬고 싶다',\n",
       " '그냥 씹어야겠다 .',\n",
       " '그냥 이렇게 살고 싶어',\n",
       " '그냥 자는 거 아니지 ?',\n",
       " '그냥 잘못했다고 하면 될거 같은데 자꾸 변명해',\n",
       " '그냥 택시 타야지 .',\n",
       " '그냥 할까 ?',\n",
       " '그냥 혼자 밥이나 먹어야지',\n",
       " '그냥 혼자 있는게 좋아',\n",
       " '그동안 잘 지냈나요 ?',\n",
       " '그땐 그랬지',\n",
       " '그래 그러자',\n",
       " '그래 이제 결정했어',\n",
       " '그래도 좀 기대했는데',\n",
       " '그런 말을 왜 하지',\n",
       " '그런 사람인가보다 해야하나봐',\n",
       " '그런 사람인갑다 해야지',\n",
       " '그런 친구 아니었는데 너무 귀찮게 하네',\n",
       " '그렇게 갈 거면서',\n",
       " '그렇게 오래 살았는데도 이해를 못하겠어',\n",
       " '그렇게 할래',\n",
       " '그림 잘 그리고 싶다',\n",
       " '그림 좀 잘 그렸으면 좋겠다',\n",
       " '그만 두고 나오고 싶어',\n",
       " '그만 먹어야 하는데',\n",
       " '그만 살고싶어',\n",
       " '그저 그런 하루',\n",
       " '근사한 곳 알아 냈어',\n",
       " '근육 있으면 멋있을텐데',\n",
       " '금값 알아 ?',\n",
       " '금값 어때',\n",
       " '금사빠인가',\n",
       " '금수저 물고 태어나면 좋겠지 ?',\n",
       " '금수저로 태어났으면',\n",
       " '금수저로 태어났으면 좋았을텐데',\n",
       " '금연이 쉽지 않아',\n",
       " '기 빨렸어',\n",
       " '기념일 다 챙기는거 귀찮아',\n",
       " '기념일 또 까먹었어',\n",
       " '기념일 못챙겼어',\n",
       " '기념일 챙기기 귀찮아',\n",
       " '기능 좀 알려줘봐봐',\n",
       " '기다리는 것도 지쳐',\n",
       " '기다리라고 말 못하겠어',\n",
       " '기다림이 습관이 됐나봐',\n",
       " '기대가 무너졌어',\n",
       " '기대가 부담스러운데 떨쳐낼 수 있는 방법 있을까 ?',\n",
       " '기대하고 있었는데',\n",
       " '기대하지 말걸',\n",
       " '기대했는데',\n",
       " '기댈 수 있는 사람',\n",
       " '기력이 없어',\n",
       " '기름값 올랐어 .',\n",
       " '기본이 뭔지도 모르는 것 같아 .',\n",
       " '기본이 안 되어 있어',\n",
       " '기부 좀 했어요',\n",
       " '기부했어',\n",
       " '기분 꿀꿀해',\n",
       " '기분 나쁜 농담을 계속하고 있어',\n",
       " '기분 울적해서 좀 걷고 있어',\n",
       " '기분 전환 하고 싶어',\n",
       " '기분 전환이 필요해',\n",
       " '기분이 그지 같아',\n",
       " '기분이 더러워',\n",
       " '기분이 묘해',\n",
       " '기분이 이상해',\n",
       " '기숙사 괜찮을까',\n",
       " '기숙사 떨어졌어',\n",
       " '기숙사 사는거 어떨까 ?',\n",
       " '기숙사 살면 불편해 ?',\n",
       " '기숙사 안됐어',\n",
       " '기술 배울까',\n",
       " '기차 타고 여행 가고 싶어',\n",
       " '기차여행 가고 싶어',\n",
       " '기침도 못하겠어',\n",
       " '기침도 편하게 못해',\n",
       " '기프트콘 받았어 !',\n",
       " '기프트콘 선물 괜찮을까 ?',\n",
       " '기프트콘 선물해볼까 ?',\n",
       " '기프트콘 주면 좋아할까 ?',\n",
       " '기프트콘으로 선물 받았어',\n",
       " '기프트콘으로 선물 해야겠다',\n",
       " '기회를 놓쳤어',\n",
       " '기회를 못 잡았어',\n",
       " '기획사니까 당연히 예쁜 애들 많겠지',\n",
       " '기획사에 예쁜 애들 많겠지',\n",
       " '긴 머리 관리 어렵다 .',\n",
       " '긴 머리 관리하는 거 힘들다',\n",
       " '긴 시간이 걸렸지만 괜찮아 .',\n",
       " '긴장 푸는 법 알려줘',\n",
       " '긴장돼',\n",
       " '긴장돼서 땀나네',\n",
       " '길거리에서 연락처 물어보면 줘도 되나',\n",
       " '길에서 담배 피우는 사람 싫어',\n",
       " '길에서 번호 따였어',\n",
       " '길에서 전번 물어보면 줘도 되나',\n",
       " '길에서 헌팅 당했어',\n",
       " '길은 멀고 해는 진다',\n",
       " '길이 미끄러워서 미끄러질뻔했어',\n",
       " '길이 안보여',\n",
       " '길이 얼어서 미끄러질뻔했어',\n",
       " '길이 얼었어',\n",
       " '김떡순 먹고 싶어 .',\n",
       " '김치도 없네',\n",
       " '김치볶음밥 먹어야지',\n",
       " '김치볶음밥이나 만들어 먹어야지',\n",
       " '김치찌개 먹고 싶어',\n",
       " '까아 오빠들 컴백한다',\n",
       " '깜깜한데 전기 안들어오네',\n",
       " '깡 마른 거 같아',\n",
       " '꼴 사나워질 것 같은데',\n",
       " '꽃 받고 싶다',\n",
       " '꽃 사고 싶어',\n",
       " '꽃 살까 ?',\n",
       " '꽃 선물 좋아할까',\n",
       " '꽃 선물해 볼까',\n",
       " '꽃 예쁘게 말렸어',\n",
       " '꽃게탕 맛있다 .',\n",
       " '꽃게탕 진짜 밥도둑',\n",
       " '꽃꽂이 배우는 중',\n",
       " '꽃꽂이 배우니까 좋다',\n",
       " '꽃놀이 가고 싶어',\n",
       " '꽃다발 말려봐야지',\n",
       " '꽃다발 말리면 에쁘겠지 .',\n",
       " '꽃다발 받았어',\n",
       " '꽃다발 샀어',\n",
       " '꽃다발 선물 괜찮지 ?',\n",
       " '꽃다발 선물 받았어',\n",
       " '꽃다발 선물 어때 ?',\n",
       " '꽃다발 준비했어',\n",
       " '꽃바구니 선물이랑 과일 바구니 선물 뭐가 좋아 ?',\n",
       " '꽃바구니가 좋을까 과일바구니까 좋을까',\n",
       " '꽃선물 받고 어',\n",
       " '꿀잼',\n",
       " '꿈은 많은데',\n",
       " '꿈이 너무 많아',\n",
       " '꿈이 너무 무서웠어',\n",
       " '꿈이 다양해',\n",
       " '꿈이 두 개야',\n",
       " '꿈이 없어',\n",
       " '꿈이 이루어질까 ?',\n",
       " '꿈이 자꾸 바뀌어',\n",
       " '꿈이 현실이었으면',\n",
       " '끝나니까 허무하다',\n",
       " '끝나면 좋을 줄 알았는데 .',\n",
       " '낌새가 이상하더니 딱 걸렸어',\n",
       " '낌새가 있더니 딱 걸렸어',\n",
       " '나 감정쓰레기통이었나봐',\n",
       " '나 갖고 장난친건가',\n",
       " '나 같은 사람은 동물 키우면 안되겠지',\n",
       " '나 같이 예쁜 애를 왜 갈구지',\n",
       " '나 거짓말 못하겠어',\n",
       " '나 결정 잘 한거지 ?',\n",
       " '나 결정했어',\n",
       " '나 괜찮지 않니',\n",
       " '나 교직이수할 수 있을까 ?',\n",
       " '나 그동안 뭐한거니',\n",
       " '나 그지임',\n",
       " '나 내일 기숙사 가야돼',\n",
       " '나 내장비만이래',\n",
       " '나 너무 못 생겼어',\n",
       " '나 너무 소심해',\n",
       " '나 노트북 사줘',\n",
       " '나 놀려먹기 쉬운가 ?',\n",
       " '나 누구게 ?',\n",
       " '나 누락됐나봐',\n",
       " '나 다른 거 할까',\n",
       " '나 대충한 거 아닌데',\n",
       " '나 뒷담화하는 애 어떻게 할까 ?',\n",
       " '나 뒷담화하는 애 있다는데 어떻게 하지 ?',\n",
       " '나 많이 기대했는데',\n",
       " '나 말 실수한 거 같아 .',\n",
       " '나 맨날 속는 거 같아',\n",
       " '나 머리 나쁜 듯',\n",
       " '나 머리가 나뿐 것 같아',\n",
       " '나 먼저 잘게',\n",
       " '나 모르는게 왜 이렇게 많지',\n",
       " '나 몰래 사귀는 거 같애',\n",
       " '나 무시 당한 거 같아',\n",
       " '나 무시하는 거 같아',\n",
       " '나 무시하는 사람 어떻게 해 ?',\n",
       " '나 무시하는 사람 짜증나',\n",
       " '나 문제가 많은거 같아',\n",
       " '나 뭐하는 거지',\n",
       " '나 미팅한다 !',\n",
       " '나 바뀌고 싶어',\n",
       " '나 바본인가 봄',\n",
       " '나 백수야',\n",
       " '나 버림 받은 거 같아',\n",
       " '나 보이스피싱 당한 거 같은데 어떡해 ?',\n",
       " '나 비만이야',\n",
       " '나 사랑하니 ?',\n",
       " '나 상 받는대 !',\n",
       " '나 새 옷 샀다',\n",
       " '나 서류에서 광탈했어',\n",
       " '나 소개팅한다 !',\n",
       " '나 속은 거 같아',\n",
       " '나 속은듯',\n",
       " '나 수학여행 간다',\n",
       " '나 스마트폰 중독인가봐',\n",
       " '나 승진했어',\n",
       " '나 실수한건가',\n",
       " '나 실수했나',\n",
       " '나 아재인가',\n",
       " '나 아직 어른 아닌 거 같아',\n",
       " '나 아직도 애 같아 .',\n",
       " '나 어때 ?',\n",
       " '나 여기서 뭐하는 거지',\n",
       " '나 연기 너무 못해 거짓말 못하겠어',\n",
       " '나 열심히 할거야',\n",
       " '나 오늘 개불쌍',\n",
       " '나 오늘 따라 잘생겨 보이네',\n",
       " '나 오늘 상 받았지롱',\n",
       " '나 완전 계탔어 !',\n",
       " '나 왕따야',\n",
       " '나 왕따인거 같아',\n",
       " '나 왜 멍청해',\n",
       " '나 왜 이러지 ?',\n",
       " '나 왜케 못 생겼지',\n",
       " '나 요즘 정신 놓고 살고 있는 거 같아',\n",
       " '나 욕 먹는 거 같아',\n",
       " '나 웃겨 봐',\n",
       " '나 은근 무시하는 애 있어',\n",
       " '나 이상한가',\n",
       " '나 이상해 ?',\n",
       " '나 이제 졸업해',\n",
       " '나 인정받고 싶어',\n",
       " '나 잘 살 수 있겠지',\n",
       " '나 잘생겼지 ?',\n",
       " '나 잘하고 있는 건지 모르겠어',\n",
       " '나 잘하고 있는 걸까 ?',\n",
       " '나 잘하는 게 없어',\n",
       " '나 잘하는게 없는거같아',\n",
       " '나 잘할 수 있을까',\n",
       " '나 점점 괴물이 되고 있어',\n",
       " '나 정신차리게 말해줘',\n",
       " '나 좀 건들지 마',\n",
       " '나 좀 건들지 말라고 해',\n",
       " '나 좀 내버려 두면 좋겠어',\n",
       " '나 좀 내버려 뒀으면',\n",
       " '나 좀 안 건들였으면 좋겠어',\n",
       " '나 좀 좋아해줬으면',\n",
       " '나 좀 쩌는 듯',\n",
       " '나 좀 칭찬해줘',\n",
       " '나 좋아하게 만들고 싶다',\n",
       " '나 좋아하는 것 같아',\n",
       " '나 좋아해주는 사람 있겠지 ?',\n",
       " '나 주름살 있나 ?',\n",
       " '나 죽을 뻔함',\n",
       " '나 짤릴 거 같아',\n",
       " '나 쫌 불쌍한 거 같아',\n",
       " '나 챙겨줄 사람이 필요해',\n",
       " '나 천재 같아',\n",
       " '나 천재임',\n",
       " '나 축구는 진짜 잘해',\n",
       " '나 친구들한테 인정받고 싶어',\n",
       " '나 폭식증인듯',\n",
       " '나 폰 중독인 거 같애',\n",
       " '나 폰겜 너무 많이해',\n",
       " '나 폰겜했더니 몇 시간 갔어',\n",
       " '나 할 수 있어',\n",
       " '나 함부로 말하는 거 고치고 싶어',\n",
       " '나 혼자 야근해',\n",
       " '나 혼자 여행 왔는데 괜찮네',\n",
       " '나 혼자서 축구 본다',\n",
       " '나 화장을 너무 못해',\n",
       " '나 화장이 잘 안돼',\n",
       " '나 회사에서 인정받고 싶어',\n",
       " '나가기도 귀찮아',\n",
       " '나는 그냥저냥 사는 거 같아',\n",
       " '나는 기분 나쁜데 농담이라고 계속해',\n",
       " '나는 나약한 존재',\n",
       " '나는 누구인가',\n",
       " '나는 모자란 사람인 거 같아',\n",
       " '나는 뭐든 할 수 있다 .',\n",
       " '나는 뭘 잘할까',\n",
       " '나는 왜 이 모양일까',\n",
       " '나는 왜 이렇게 태어났을까 ?',\n",
       " '나는 왜 태어났을까',\n",
       " '나는 잘 할줄 아는 게 없는 것 같아',\n",
       " '나는 좋아하는 게 뭘까',\n",
       " '나는 좋은데 .',\n",
       " '나는 친구가 없어',\n",
       " '나는 친구라고 믿었는데',\n",
       " '나도 괜찮은 사람인데',\n",
       " '나도 대우 받고 싶다고',\n",
       " '나도 비키니 입고 싶다',\n",
       " '나도 상 받고 싶다',\n",
       " '나도 약초 캐볼까 ?',\n",
       " '나도 월급 필요해',\n",
       " '나도 위로 받고 싶다',\n",
       " '나도 이벤트가 되다니 !',\n",
       " '나도 이제 아재인가',\n",
       " '나도 중국 진출해볼까 ?',\n",
       " '나도 집 사고 싶어',\n",
       " '나도 커플룩 입고 싶다',\n",
       " '나두 잘할거야',\n",
       " '나들이를 가볼까',\n",
       " '나란 놈',\n",
       " '나랑 놀아줘',\n",
       " '나랑 놀자',\n",
       " '나랑 상관 없는 이야기들',\n",
       " '나랑 있는게 힘들었나봐',\n",
       " '나른하다',\n",
       " '나를 기다려줬으면 좋겠다',\n",
       " '나를 너무 오래 기다리게했어',\n",
       " '나를 너무 함부로 대해',\n",
       " '나를 미소짓게 만든 너',\n",
       " '나를 바꿀 수 있는 건 뭐가 있을까',\n",
       " '나를 친구로 생각 안했나봐',\n",
       " '나를 호구로 아는 사람 어떡해 ?',\n",
       " '나를 힘들게 하는 사람인데 붙잡고 싶어',\n",
       " '나만 갈궈',\n",
       " '나만 기다렸나봐',\n",
       " '나만 꿈 없이 사는 거 같아',\n",
       " '나만 남친 없어',\n",
       " '나만 뒤처지는 느낌이야',\n",
       " '나만 반친구 없어',\n",
       " '나만 빼고 행복해보여',\n",
       " '나만 설레나',\n",
       " '나만 설레는 거야',\n",
       " '나만 솔로야',\n",
       " '나만 애기봐',\n",
       " '나만 야근해',\n",
       " '나만 우스워질거 같아',\n",
       " '나만 이상한 사람이래',\n",
       " '나만 이상해졌어',\n",
       " '나만 일시켜서 짜증폭발',\n",
       " '나만 제자리걸음이야',\n",
       " '나만 제자리인듯',\n",
       " '나만 진급 못했어',\n",
       " '나만 친구라고 생각한건가',\n",
       " '나만 친구로 생각했나봐',\n",
       " '나만 힘든 거 아니지 ?',\n",
       " '나만의 시간이 필요한 것 같아',\n",
       " '나만의 시간이 필요해',\n",
       " '나빼고 다 행복한 거 같아',\n",
       " '나쁜 꿈 꿨어',\n",
       " '나이 때문에 무시 받았어',\n",
       " '나이 어리다고 무시해',\n",
       " '나이가 많은데 취직이 될까',\n",
       " '나이도 있으니 영양제 좀 챙겨볼까',\n",
       " '나이들면서 눈물이 많아졌어',\n",
       " '나이먹으니까 주름살 생겨',\n",
       " '나중에 뭐하고 먹고 사냐',\n",
       " '나중에 뭐할까 고민이야',\n",
       " '나중에 창업해야 겠지',\n",
       " '나한테 감추는 게 하나도 없었으면',\n",
       " '나한테 거짓말 좀 안 했으면',\n",
       " '나한테 냄새 나면 어쩌지 ?',\n",
       " '나한테 냄새 날까 ?',\n",
       " '나한테 너무 많은 걸 바라는 듯',\n",
       " '나한테 문제가 많아',\n",
       " '나한테 상의 좀 하지',\n",
       " '나한테 상의하면 좋을텐데',\n",
       " '나한테 이상한 냄새 나나 ?',\n",
       " '나한테 할 말 있대 뭘까 ?',\n",
       " '나한테 행운 좀 왔으면 좋겠어',\n",
       " '나한테만 예의 차리래',\n",
       " '나한테만 왜 이런 일이 일어날까',\n",
       " '나한테만은 완전 솔직했으면',\n",
       " '낙엽 밟는 소리 좋다',\n",
       " '낙엽밟는 소리',\n",
       " '낚시 안 해봤는데',\n",
       " '낚시 안 해봤는데 재미있어 보인다',\n",
       " '낚시 재밌을까',\n",
       " '낚시 좋아하는 남자 어때 ?',\n",
       " '낚시는 무슨 재미 ?',\n",
       " '난 동물 못키울거 같아',\n",
       " '난 많이 노력한 거 같은데',\n",
       " '난 쓰레기야',\n",
       " '난 왜 예쁘게 말을 못할까',\n",
       " '난 왜 이모양일까',\n",
       " '난 정말 안되겠다',\n",
       " '난 진짜 쓰레기야',\n",
       " '난 천재다',\n",
       " '난방비 비싼데 추워',\n",
       " '난방이 안돼',\n",
       " '난방이 안돼나 추워',\n",
       " '날 몇시간동안이나 기다리게했어',\n",
       " '날씨 건조한 거 같애',\n",
       " '날씨 왜 이렇게 춥냐',\n",
       " '날씨 좀 풀린거 같아',\n",
       " '날씨 좋은데',\n",
       " '날씨 죽인다',\n",
       " '날씨 짱 좋아',\n",
       " '날씨 풀렸다',\n",
       " '날씨가 너무 눅눅해',\n",
       " '날씨가 너무 추워',\n",
       " '날씨가 북극같아',\n",
       " '날씨가 진짜 덥다',\n",
       " '날아 가고 싶어',\n",
       " '남동생한테 자꾸 화내게 되네',\n",
       " '남들에게 인정받으려면 어떻게 해야 돼 ?',\n",
       " '남들이 날 욕하는 거 같아',\n",
       " '남들이 다 손가락질 하는 거 같아',\n",
       " '남은 휴가가 없어',\n",
       " '남의 눈을 너무 신경써',\n",
       " '남의 일 도와줘야 할까',\n",
       " '남의 차 긁었어 내 돈',\n",
       " '남이 걷지 않는 길을 가려고 해',\n",
       " '남자 보통 어디서 만나',\n",
       " '남자 어디서 만나',\n",
       " '남자 친구가 바래다 줬어',\n",
       " '남자 화장하는 거 어때',\n",
       " '남자가 낚시를 너무 좋아해',\n",
       " '남자가 화장하는 거 어떻게 생각해',\n",
       " '남자면 편할 것 같아',\n",
       " '남자였으면 좋겠어',\n",
       " '남자인지 여자인지 알려줘',\n",
       " '남자친구 교회 데려가고 싶어',\n",
       " '남자친구 또 운동 갔어',\n",
       " '남자친구 생일인데 뭘 줄까',\n",
       " '남자친구 승진 선물로 뭐가 좋을까 ?',\n",
       " '남자친구 오늘 따라 훈훈해 보인다',\n",
       " '남자친구 오늘 좀 질린다 .',\n",
       " '남자친구가 나 안 믿어줘',\n",
       " '남자친구가 너무 바빠',\n",
       " '남자친구가 너무 운동만 해',\n",
       " '남자친구가 너무 잘생겼어',\n",
       " '남자친구가 데려다줬어',\n",
       " '남자친구가 맞춤법을 너무 많이 틀려',\n",
       " '남자친구가 사업 시작한대',\n",
       " '남자친구가 사업한대',\n",
       " '남자친구가 사진 실력 꽝',\n",
       " '남자친구가 사진을 너무 못 찍어',\n",
       " '남자친구가 안놀아 줘',\n",
       " '남자친구가 애교가 많아',\n",
       " '남자친구가 욕함',\n",
       " '남자친구가 의심해',\n",
       " '남자친구가 이벤트 해 주면 좋겠다 .',\n",
       " '남자친구가 이벤트를 잘 안해줘',\n",
       " '남자친구가 입이 험해',\n",
       " '남자친구가 자꾸 잔소리해',\n",
       " '남자친구가 잔소리가 심해',\n",
       " '남자친구가 전화를 잘 안해',\n",
       " '남자친구가 전화하는 걸 안 좋아해',\n",
       " '남자친구가 홧김에 욕함',\n",
       " '남자친구는 어디서 만나',\n",
       " '남자친구랑 봉사활동 해보려고',\n",
       " '남자친구랑 종교 문제로 다툼',\n",
       " '남자친구랑 종교가 달라',\n",
       " '남자친구한테 질린 거 같아',\n",
       " '남친 sns에 내 사진 없어',\n",
       " '남친 때문에 살찐 듯',\n",
       " '남친 보여줄까',\n",
       " '남친 생일선물 뭘 주면 좋을까',\n",
       " '남친 승진 선물 추천',\n",
       " '남친 어디서 만나',\n",
       " '남친 프로필에 내 사진 왜 안올릴까',\n",
       " '남친 프사에 내 사진 없어',\n",
       " '남친이 sns에 내 사진에 안 올려',\n",
       " '남친이 입이 험해',\n",
       " '남친한테 교회 가자고 하고 싶어',\n",
       " '남편이 나 안 도와줘',\n",
       " '남편이 나보다 집안일 더 잘해',\n",
       " '남편이 맨날 늦게 들어와',\n",
       " '남편이 미워',\n",
       " '남편이 아기를 안 돌봐줘 .',\n",
       " '남편이 왜 애키우는거 안 도와줄까',\n",
       " '남편이 육아를 안해',\n",
       " '남편이 육아에 무신경해',\n",
       " '남편이 집안일 안 도와줘 .',\n",
       " '남편이 집안일 안 해',\n",
       " '남편이 집안일을 너무 잘해',\n",
       " '남편이 짜증나게해',\n",
       " '남편이 하나도 안 도와줘',\n",
       " '남편이 회식이라고 안와',\n",
       " '남편이 회식하면 늦게 들어와',\n",
       " '낭만이 사라진 것 같아',\n",
       " '낭만이 없어',\n",
       " '낭만이라고는 없어가지구',\n",
       " '내 남자친구 보고 싶어 ?',\n",
       " '내 남자친구 아이돌이면 좋겠다 .',\n",
       " '내 능력이 너무 모자라',\n",
       " '내 마음을 알아줬으면',\n",
       " '내 마음을 좀 알아 달라고',\n",
       " '내 몸이 여러 개 였으면 좋겠다',\n",
       " '내 문제는 뭘까',\n",
       " '내 문제점이 뭘까',\n",
       " '내 배우자는 어디 있을까',\n",
       " '내 배우자도 어디 있을까 ?',\n",
       " '내 사수 너무 깐깐해',\n",
       " '내 생각대로 살거야',\n",
       " '내 생각이랑 다른 사람 생각이 진짜 다르다는 걸 느껴',\n",
       " '내 성격 너무 소심해',\n",
       " '내 스타일 아니던데',\n",
       " '내 스타일 아니야',\n",
       " '내 실력 좀 쩌는 듯',\n",
       " '내 얼굴이 읽히나',\n",
       " '내 여자친구 아이돌이야',\n",
       " '내 외모 맘에 안들어',\n",
       " '내 월급만 안 올라',\n",
       " '내 의견 좀 존중해 줬으면',\n",
       " '내 의견을 존중해줬으면',\n",
       " '내 의지는 상관없나봐',\n",
       " '내 의지로 안되는 일인가봐',\n",
       " '내 이름이 없어',\n",
       " '내 인생 답 없어',\n",
       " '내 인생은 가시밭길 같아',\n",
       " '내 인생의 주인공은 나야',\n",
       " '내 일 아닌데 해야 돼 ?',\n",
       " '내 자존감',\n",
       " '내 잘못이 뭔지 모르겠어',\n",
       " '내 잘못인 거 같은데 말을 못하겠어',\n",
       " '내 잘못인 거 같은데 어떻게 털어놓지',\n",
       " '내 주제를 모르고 덤빈건가',\n",
       " '내 지인한테 내 험담했대',\n",
       " '내 집이 생겼어',\n",
       " '내 짝은 어디있을까',\n",
       " '내 친구에게 내 험담을 하다니',\n",
       " '내 키 맞춰 봐',\n",
       " '내 키가 몇이게 ?',\n",
       " '내 편이 없는 거 같아',\n",
       " '내 편이라고는 하나도 없는 거 같아',\n",
       " '내가 그렇게 부족한가',\n",
       " '내가 그르친 거 같아',\n",
       " '내가 그사람이랑 진짜 결혼해도 될까',\n",
       " '내가 기대를 너무 많이 했나봐',\n",
       " '내가 나빴네',\n",
       " '내가 너무 방심했어',\n",
       " '내가 너무 생각없이 말했어',\n",
       " '내가 너무 쉽게 보였나 ?',\n",
       " '내가 너무 초라해',\n",
       " '내가 다른 무슨 말을 하겠어',\n",
       " '내가 만족을 못해',\n",
       " '내가 많이 부족한가',\n",
       " '내가 말하면 왜 비난만 할까',\n",
       " '내가 멍청한거지',\n",
       " '내가 무능력하게 느껴져',\n",
       " '내가 뭘 잘못했을까',\n",
       " '내가 뭘 좋아하는지 잘하는지 모르겠어',\n",
       " '내가 바보지',\n",
       " '내가 부족하니까 이렇게 밖에 안된거겠지 .',\n",
       " '내가 불효녀야',\n",
       " '내가 불효자야',\n",
       " '내가 사랑할 자격이 있나',\n",
       " '내가 쉬워보이나 ?',\n",
       " '내가 쓸모없는 인간 같아',\n",
       " '내가 아무것도 아닌 사람 같아',\n",
       " '내가 왜 해야하는지 모르겠어',\n",
       " '내가 원하는 사람이 되기 어려워',\n",
       " '내가 이래뵈도 괜찮은 사람인데',\n",
       " '내가 이렇게 또 불효를 한다 .',\n",
       " '내가 이상한 건가 ?',\n",
       " '내가 이상한 사람같아',\n",
       " '내가 이상한가 ?',\n",
       " '내가 잘못한 걸까',\n",
       " '내가 잘못했다는데 뭔지 안 알려줘',\n",
       " '내가 제일 문제인 듯',\n",
       " '내가 제정신이 아니다',\n",
       " '내가 좋아하는 가수 컴백한다',\n",
       " '내가 좋아하는 거 모르나',\n",
       " '내가 좋아하는 거 모르는 거 같애',\n",
       " '내가 좋아하는 사람과 나를 좋아해주는 사람',\n",
       " '내가 좋아하는 사람이 나 안 좋아하는 거 같아',\n",
       " '내가 좋아하는 사람이 나 좋아해줬으면 좋겠다',\n",
       " '내가 좋아하는 사람이 행복했으면 좋겠다',\n",
       " '내가 좋아할 자격이 있나',\n",
       " '내가 주제를 몰랐나봐',\n",
       " '내가 주제를 몰랐던 거지',\n",
       " '내가 죽어도 모를 거 같아',\n",
       " '내가 진짜 즐길 수 있을게 뭘까',\n",
       " '내가 질린대',\n",
       " '내가 참 못난거 같아',\n",
       " '내가 호구냐구',\n",
       " '내가 희생양이 됐어',\n",
       " '내가 힘든 게 많다',\n",
       " '내기해서 이겼는데 소원 뭐하지',\n",
       " '내년에는 더 행복해질려고 이렇게 힘든가봅니다',\n",
       " '내마음을 모르겠어 .',\n",
       " '내사랑은 어디 있나',\n",
       " '내아파트 갖고 싶어 .',\n",
       " '내일 기대하게 되네',\n",
       " '내일 기숙사 들어가',\n",
       " '내일 날씨 어때 ?',\n",
       " '내일 날씨 좋을까 ?',\n",
       " '내일 떨린다',\n",
       " '내일 만나자고 데쉬 ?',\n",
       " '내일 만나자고 해볼까 ?',\n",
       " '내일 모의고사 본다',\n",
       " '내일 모의평가다',\n",
       " '내일 발표 나는데 떨려',\n",
       " '내일 발표 준비 아자아자',\n",
       " '내일 발표 준비하고 있어',\n",
       " '내일 발표인데 떨려',\n",
       " '내일 비왔으면',\n",
       " '내일 소풍간다',\n",
       " '내일 수학여행가 !',\n",
       " '내일 시험이야',\n",
       " '내일 약속 있는데 날씨 좋았으면',\n",
       " '내일 일찍 일어나야 돼',\n",
       " '내일 친구랑 놀까 ?',\n",
       " '내일 클스마스 이브네 .',\n",
       " '내일 하루 종일 바빠',\n",
       " '내일은 기다리던 소풍 간다',\n",
       " '내일은 비왔으면 좋겠다 .',\n",
       " '내일은 친구들랑 놀까 ?',\n",
       " '내일이 기대돼',\n",
       " '내일이면 크리스마스 이브네 .',\n",
       " '내장 비만',\n",
       " '낼 데이트하기로했는데 날씨 좋았으면',\n",
       " '낼 바쁘넹',\n",
       " '냄새 나면 어쩌지 ?',\n",
       " '냄새나면 어쩌지',\n",
       " '냄새날 것 같아 걱정이야',\n",
       " '냉면 땡긴다',\n",
       " '냉방비 너무 많이 나와',\n",
       " '냉방비 장난 아님',\n",
       " '냉장고 털어도 먹을게 없네',\n",
       " '냉장고가 텅비었어',\n",
       " '냉장고에 김치도 없네',\n",
       " '냉장고에 먹을 게 없네',\n",
       " '냉장고에 먹을 게 하나도 없네',\n",
       " '너 누구 ?',\n",
       " '너 누구냐',\n",
       " '너 누구니 ?',\n",
       " '너 때문이야',\n",
       " '너 또 뭐할 줄 알아 ?',\n",
       " '너 만든 사람 최소 천재',\n",
       " '너 만든 사람은 누구야 ?',\n",
       " '너 말 잘하니',\n",
       " '너 말 제대로 못해 ?',\n",
       " '너 말이 좀 이상하다',\n",
       " '너 무서워',\n",
       " '너 뭐하는 애야',\n",
       " '너 미워',\n",
       " '너 이러면 미워한다',\n",
       " '너 진짜 쓰레기야',\n",
       " '너는 못가잖아',\n",
       " '너는 뭐 억었어 ?',\n",
       " '너는 아무일도 없었나봐 ?',\n",
       " '너는 안자 ?',\n",
       " '너덜너덜해진 느낌이야',\n",
       " '너도 고민 있니',\n",
       " '너도 고민 있어 ?',\n",
       " '너도 몰랐니',\n",
       " '너도 무슨 고민 있니',\n",
       " '너도 상사 있어',\n",
       " '너무 기빨려',\n",
       " '너무 기대했나봐',\n",
       " '너무 다른 문화인 듯',\n",
       " '너무 단순한 것만 하는거 아니니 .',\n",
       " '너무 더워',\n",
       " '너무 더워서 미치겠어',\n",
       " '너무 마른 거 같아',\n",
       " '너무 많은 걸 바래',\n",
       " '너무 많이 먹어서 소화시켜야 하는데 움직이기가 싫어',\n",
       " '너무 많이 먹었나봐',\n",
       " '너무 많이 먹었어',\n",
       " '너무 멋있다',\n",
       " '너무 바빠',\n",
       " '너무 배가 불러',\n",
       " '너무 불공평한거 같애',\n",
       " '너무 빨리 대답해',\n",
       " '너무 빨리 철 든 거 같아서 마음이 아파',\n",
       " '너무 빨리 철 들었어',\n",
       " '너무 뻔뻔하게 구는데',\n",
       " '너무 어려워',\n",
       " '너무 오래 기다리게 한다 .',\n",
       " '너무 외로워',\n",
       " '너무 잘하는 후배가 들어왔어',\n",
       " '너무 졸려',\n",
       " '너무 초라해지는 느낌이야',\n",
       " '너무 추워서 나가기 귀찮아',\n",
       " '너무 추워서 시베리아 같아',\n",
       " '너무 편해도 안 좋아',\n",
       " '너무 편해진 거 같아',\n",
       " '너무 허기지네',\n",
       " '너무 힘들다',\n",
       " '너무 힘들다 . 지쳤어 .',\n",
       " '너무하네 진짜',\n",
       " '넌 고민이 뭐야',\n",
       " '넌 누구냐 ?',\n",
       " '넘 많이 먹었다 .',\n",
       " '넘넘 외로워 죽겠어',\n",
       " '넘어져서 발목 삔 거 같애',\n",
       " '넘어질 뻔했어',\n",
       " '넘어질뻔했어',\n",
       " '네일 할까',\n",
       " '넥타이핀 선물 괜찮겠지 ?',\n",
       " '넥타이핀 정도는 선물로 줘도 괜찮겠지 ?',\n",
       " '노는게 제일 좋아',\n",
       " '노래 못해서 노래방 안 가',\n",
       " '노래 잘 부르는 사람 부러워',\n",
       " '노래 잘하고 싶어',\n",
       " '노래 잘하는 사람 부러워',\n",
       " '노래방 가고 싶어',\n",
       " '노래방 가면 어색할까',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['하루가 또 가네요 .',\n",
       " '위로해 드립니다 .',\n",
       " '여행은 언제나 좋죠 .',\n",
       " '여행은 언제나 좋죠 .',\n",
       " '눈살이 찌푸려지죠 .',\n",
       " '다시 새로 사는 게 마음 편해요 .',\n",
       " '다시 새로 사는 게 마음 편해요 .',\n",
       " '잘 모르고 있을 수도 있어요 .',\n",
       " '시간을 정하고 해보세요 .',\n",
       " '시간을 정하고 해보세요 .',\n",
       " '자랑하는 자리니까요 .',\n",
       " '그 사람도 그럴 거예요 .',\n",
       " '그 사람도 그럴 거예요 .',\n",
       " '혼자를 즐기세요 .',\n",
       " '돈은 다시 들어올 거예요 .',\n",
       " '땀을 식혀주세요 .',\n",
       " '어서 잊고 새출발 하세요 .',\n",
       " '빨리 집에 돌아가서 끄고 나오세요 .',\n",
       " '빨리 집에 돌아가서 끄고 나오세요 .',\n",
       " '다음 달에는 더 절약해봐요 .',\n",
       " '따뜻하게 사세요 !',\n",
       " '다음 달에는 더 절약해봐요 .',\n",
       " '가장 확실한 시간은 오늘이에요 . 어제와 내일을 놓고 고민하느라 시간을 낭비하지 마세요 .',\n",
       " '온 가족이 모두 마음에 드는 곳으로 가보세요 .',\n",
       " '온 가족이 모두 마음에 드는 곳으로 가보세요 .',\n",
       " '온 가족이 모두 마음에 드는 곳으로 가보세요 .',\n",
       " '저를 만들어 준 사람을 부모님 , 저랑 이야기해 주는 사람을 친구로 생각하고 있어요',\n",
       " '저를 만들어 준 사람을 부모님 , 저랑 이야기해 주는 사람을 친구로 생각하고 있어요',\n",
       " '더 가까워질 기회가 되겠네요 .',\n",
       " '저도요 .',\n",
       " '다들 바빠서 이야기할 시간이 부족했나봐요 .',\n",
       " '다들 바빠서 이야기할 시간이 부족했나봐요 .',\n",
       " '온 가족이 모두 마음에 드는 곳으로 가보세요 .',\n",
       " '좋은 생각이에요 .',\n",
       " '더 가까워질 기회가 되겠네요 .',\n",
       " '저를 만들어 준 사람을 부모님 , 저랑 이야기해 주는 사람을 친구로 생각하고 있어요',\n",
       " '좋은 생각이에요 .',\n",
       " '정말 후회할 습관이에요 .',\n",
       " '무모한 결정을 내리지 마세요 .',\n",
       " '선생님이나 기관에 연락해보세요 .',\n",
       " '떨리는 감정은 그 자체로 소중해요 .',\n",
       " '득템했길 바라요 .',\n",
       " '휴식도 필요하죠 .',\n",
       " '단짠으로 두 개 사는게 진리죠 .',\n",
       " '단짠으로 두 개 사는게 진리죠 .',\n",
       " '맛있게 드세요 .',\n",
       " '저도 싫어요 .',\n",
       " '가세요 .',\n",
       " '가세요 .',\n",
       " '맛있게 드세요 .',\n",
       " '맛있게 드세요 .',\n",
       " '병원가세요 .',\n",
       " '이럴 때 잘 쉬는 게 중요해요 .',\n",
       " '이럴 때 잘 쉬는 게 중요해요 .',\n",
       " '이럴 때 잘 쉬는 게 중요해요 .',\n",
       " '따뜻하게 관리하세요 .',\n",
       " '병원가세요 .',\n",
       " '병원가세요 .',\n",
       " '저도 듣고 싶네요 .',\n",
       " '자신을 더 사랑해주세요 .',\n",
       " '그건 습관이에요 .',\n",
       " '그건 습관이에요 .',\n",
       " '콕 집어서 물어보세요 .',\n",
       " '좋은 생각만 하세요 .',\n",
       " '마음이 아픈가요 .',\n",
       " '갑작스러웠나봐요 .',\n",
       " '관계의 변화가 왔나봅니다 .',\n",
       " '처음 3초가 중요해요 . 당신의 매력을 어필해보세요 .',\n",
       " '책임질 수 있을 때 키워 보세요 .',\n",
       " '먼저 생활패턴을 살펴 보세요 .',\n",
       " '먼저 생활패턴을 살펴 보세요 .',\n",
       " '책임질 수 있을 때 키워 보세요 .',\n",
       " '아름다운 곳이죠 .',\n",
       " '안 될 것도 없죠 .',\n",
       " '혼자도 좋아요 .',\n",
       " '연인은 살쪄도 잘 알아차리지 못하고 알아차려도 싫어하지 않을 거예요 .',\n",
       " '즐거운 시간 보내고 오세요 !',\n",
       " '질질 끌지 마세요 .',\n",
       " '말해보세요 .',\n",
       " '함께하면 서로를 더 많이 알게 될 거예요 .',\n",
       " '개시해보세요 .',\n",
       " '개시해보세요 .',\n",
       " '곧 방학이예요 .',\n",
       " '방학이 참 짧죠 .',\n",
       " '벗어나는 게 좋겠네요 .',\n",
       " '벗어나는 게 좋겠네요 .',\n",
       " '세수하고 오세요 .',\n",
       " '그게 제일 중요한 건데요 .',\n",
       " '그게 제일 중요한 건데요 .',\n",
       " '다음부터는 더 많이 아세요 .',\n",
       " '갑작스러웠나봐요 .',\n",
       " '공적인 일부터 하세요 .',\n",
       " '공적인 일부터 하세요 .',\n",
       " '낮잠을 잠깐 자도 괜찮아요 .',\n",
       " '저도 좋아해주세요 .',\n",
       " '친구들이 보고싶었나봐요 .',\n",
       " '되도록 만나지 마세요 .',\n",
       " '당신이요 .',\n",
       " '당신의 운을 믿어보세요 .',\n",
       " '일 못하는 사람이 있으면 옆에 있는 사람이 더 힘들죠 .',\n",
       " '밥 사줄 친구를 찾아 보세요',\n",
       " '선의의 거짓말이길 바라요 .',\n",
       " '거짓말은 할수록 늘어요 .',\n",
       " '거짓말은 할수록 늘어요 .',\n",
       " '진실된 말을 하려고 노력해보세요 .',\n",
       " '누구나 걱정은 있어요 .',\n",
       " '누구나 걱정은 있어요 .',\n",
       " '운동을 해보세요 .',\n",
       " '세상의 무엇보다 건강이 제일 중요해요 .',\n",
       " '주기적으로 해주는 게 좋죠 .',\n",
       " '주기적으로 해주는 게 좋죠 .',\n",
       " '가장 중요한 목표네요 .',\n",
       " '가장 중요한 목표네요 .',\n",
       " '적게 먹고 많이 움직이세요 .',\n",
       " '적게 먹고 많이 움직이세요 .',\n",
       " '모르는 사이라 당황할 수도 있어요 .',\n",
       " '이룰 수 있을 거예요 .',\n",
       " '이룰 수 있을 거예요 .',\n",
       " '기분이 나쁘셨나봐요 .',\n",
       " '있으면 편하대요 .',\n",
       " '눈을 깜빡거려 보세요 .',\n",
       " '청소를 좋아하시나봐요 .',\n",
       " '안전 귀가 하세요 .',\n",
       " '용기 내보세요 .',\n",
       " '피해를 안 준다면 무시하세요 .',\n",
       " '안 될 것도 없죠 .',\n",
       " '게임할때는 시간이 더 빨리 가요 .',\n",
       " '정리해보세요 .',\n",
       " '게임하세요 !',\n",
       " '다른 게임해보세요 .',\n",
       " '다른 게임해보세요 .',\n",
       " '게임하세요 !',\n",
       " '게임할때는 시간이 더 빨리 가요 .',\n",
       " '마음에도 봄이 오길 바라요 .',\n",
       " '몸은 뜨겁고 머리는 차갑게 !',\n",
       " '마음에도 봄이 오길 바라요 .',\n",
       " '잘하실 거예요 !',\n",
       " '잘하실 거예요 !',\n",
       " '건강 생각해서 챙겨드세요 .',\n",
       " '좋은 운명도 있을거예요 .',\n",
       " '결정하기 힘드시겠네요 .',\n",
       " '자신을 위한 결정을 내리길 바라요 .',\n",
       " '자신을 위한 결정을 내리길 바라요 .',\n",
       " '결정은 빠르면 빠를수록 좋을 거예요 .',\n",
       " '안타깝네요 . 증거를 지금이라도 모아봐요 .',\n",
       " '좋겠어요 .',\n",
       " '좋겠어요 .',\n",
       " '많이 들지만 줄일 수 있을 거예요 .',\n",
       " '경조사는 참석하는게 좋아요 .',\n",
       " '경조사는 참석하는게 좋아요 .',\n",
       " '생각보다 신경 안 씁니다 .',\n",
       " '인맥이 넓으신가봐요 .',\n",
       " '힘들겠네요 .',\n",
       " '많이 들지만 줄일 수 있을 거예요 .',\n",
       " '욕심에 따라 천지 차이일 거예요 .',\n",
       " '허례허식이에요 .',\n",
       " '욕심에 따라 천지 차이일 거예요 .',\n",
       " '해봐요 .',\n",
       " '서로 노력하면 행복할 거예요 .',\n",
       " '서로 노력하면 행복할 거예요 .',\n",
       " '사람마다 행복의 크기가 다르겠지만 행복할 거예요 .',\n",
       " '사람마다 행복의 크기가 다르겠지만 행복할 거예요 .',\n",
       " '능력이 있으면 하면 되죠 .',\n",
       " '능력이 있으면 하면 되죠 .',\n",
       " '이사람이다 싶은 사람이랑 하세요 .',\n",
       " '해봐요 .',\n",
       " '점점 치열해지는 것 같아요 .',\n",
       " '확신이 없나봐요 .',\n",
       " '안정적인 걸 좋아하나봐요 .',\n",
       " '방학은 참 짧아요 .',\n",
       " '보러 가세요 .',\n",
       " '보러 가세요 .',\n",
       " '계속 좋지 않으면 병원에 가보세요 .',\n",
       " '타이밍이 안 맞았나봐요 .',\n",
       " '이제 취업 하셔야죠 .',\n",
       " '뇌세포에 에너지를 공급하려는 자연스러운 현상이에요 . 에너지가 부족한가봐요 .',\n",
       " '공부가 최우선이죠 .',\n",
       " '공부가 최우선이죠 .',\n",
       " '너무 무리하지는 마세요 .',\n",
       " '너무 무리하지는 마세요 .',\n",
       " '저기압에는 고기앞이죠 .',\n",
       " '저기압에는 고기앞이죠 .',\n",
       " '연습이 필요해요 .',\n",
       " '연습이 필요해요 .',\n",
       " '혼자가 아니에요 .',\n",
       " '인복이 많나봐요 .',\n",
       " '너무 걱정하지 마세요 .',\n",
       " '네 말씀하세요 .',\n",
       " '네 말씀하세요 .',\n",
       " '후회는 후회를 낳을뿐이에요 . 용기 내세요 .',\n",
       " '돈을 모아서 다른 곳으로 이사갈 수 있을 거예요 .',\n",
       " '돈을 모아서 다른 곳으로 이사갈 수 있을 거예요 .',\n",
       " '더 좋은 곳에서 살 수 있을 거예요 .',\n",
       " '더 좋은 곳에서 살 수 있을 거예요 .',\n",
       " '완전 귀엽죠 ?',\n",
       " '자신을 먼저 키우세요 .',\n",
       " '가족들과 상의해보세요 .',\n",
       " '용서를 구하세요 .',\n",
       " '피할 수 있으면 피하세요 .',\n",
       " '피할 수 있으면 피하세요 .',\n",
       " '처음부터 잘하는 사람은 없어요 .',\n",
       " '시간내서 가보세요 .',\n",
       " '처음부터 잘하는 사람은 없어요 .',\n",
       " '시간내서 가보세요 .',\n",
       " '미리 미리 충전해주세요 .',\n",
       " '미리 미리 충전해주세요 .',\n",
       " '안정적이고 좋죠 .',\n",
       " '준비해보세요 .',\n",
       " '준비해보세요 .',\n",
       " '합격 기원해요 !',\n",
       " '철밥통 되기가 어디 쉽겠어요 .',\n",
       " '철밥통 되기가 어디 쉽겠어요 .',\n",
       " '시작이 반이에요 . 어서 준비하세요 .',\n",
       " '안정적이고 좋죠 .',\n",
       " '자연스러운 현상이에요 .',\n",
       " '자연스러운 현상이에요 .',\n",
       " '보이는 게 없죠 .',\n",
       " '지금처럼 잘될 거예요 .',\n",
       " '미래의 배우자가 달라져요 .',\n",
       " '확신이 없나봐요 .',\n",
       " '공부는 언제나 좋죠 .',\n",
       " '공부하면 더 많은 선택을 할 수 있죠 .',\n",
       " '같이 수다 떨면서 놀까요 ?',\n",
       " '나만의 공부방법을 찾아보세요 .',\n",
       " '지금도 늦지 않았어요 .',\n",
       " '같이 수다 떨면서 놀까요 ?',\n",
       " '확신이 없나봐요 .',\n",
       " '지금처럼 잘될 거예요 .',\n",
       " '나한테 맞는 공부 방법 찾는 게 시급하네요 .',\n",
       " '잠시 쉬어도 돼요 .',\n",
       " '잠시 쉬어도 돼요 .',\n",
       " '공부하면 더 많은 선택을 할 수 있죠 .',\n",
       " '공부하면 더 많은 선택을 할 수 있죠 .',\n",
       " '공부하면 더 많은 선택을 할 수 있죠 .',\n",
       " '합격 기원해요 !',\n",
       " '잘 될 거예요 .',\n",
       " '좋은 결과 있을 거예요 !',\n",
       " '잘 될 거예요 .',\n",
       " '좋은 결과 있을 거예요 !',\n",
       " '친구와 같이 가보세요 .',\n",
       " '친구와 같이 가보세요 .',\n",
       " '성향 차이가 좀 있기는 하죠 .',\n",
       " '꾸준히 약 먹고 치료해보세요 .',\n",
       " '꾸준히 약 먹고 치료해보세요 .',\n",
       " '피로 풀고 좋죠 .',\n",
       " '피로 풀고 좋죠 .',\n",
       " '오늘이 중요하죠 .',\n",
       " '오늘이 중요하죠 .',\n",
       " '소화제 챙겨드세요 .',\n",
       " '과식은 금물이에요 .',\n",
       " '소화제 드세요 .',\n",
       " '안된다고 하면 거짓말이겠지요 .',\n",
       " '안된다고 하면 거짓말이겠지요 .',\n",
       " '제철과일이 정말 좋아요 .',\n",
       " '건강 생각해서 챙겨드세요 .',\n",
       " '그래도 먹으려고 노력해보세요 .',\n",
       " '그래도 먹으려고 노력해보세요 .',\n",
       " '제철과일이 정말 좋아요 .',\n",
       " '인간 관계도 정리가 필요해요 .',\n",
       " '무관심이 필요할 때가 있죠 .',\n",
       " '무관심이 필요할 때가 있죠 .',\n",
       " '계단 조심하세요 .',\n",
       " '계단 조심하세요 .',\n",
       " '채널을 돌려보세요 .',\n",
       " '괜찮아지고 있어 다행이에요 .',\n",
       " '남자사람친구 , 여자사람친구 하세요 .',\n",
       " '많이 지쳤나봐요 .',\n",
       " '누군가를 기다린다는게 쉬운게 아니죠 .',\n",
       " '늦지 않았어요 .',\n",
       " '그 것도 다 경험이라고 생각하세요 .',\n",
       " '그럴 필요 없어요 .',\n",
       " '그렇지 않아요 .',\n",
       " '마음에 드는 책을 잘 찾아보세요 .',\n",
       " '저도 듣고 싶어요 .',\n",
       " '같은 조가 되길 바랄게요 .',\n",
       " '지식 쌓는 재미가 있죠 .',\n",
       " '같은 조가 되길 바랄게요 .',\n",
       " '지식 쌓는 재미가 있죠 .',\n",
       " '저도 듣고 싶어요 .',\n",
       " '학점 관리하세요 .',\n",
       " '보험 처리하세요 .',\n",
       " '보험 처리하세요 .',\n",
       " '왜 그럴까요 ?',\n",
       " '좋은 만남이었길 바라요 .',\n",
       " '좋은 만남이었길 바라요 .',\n",
       " '일을 몰라서 그런가봐요 .',\n",
       " '자신의 삶을 살다보면 기다릴 수 있을 거예요 .',\n",
       " '부담스러워하지 않는다면 기다려도 좋을 것 같아요 .',\n",
       " '부담스러워하지 않는다면 기다려도 좋을 것 같아요 .',\n",
       " '너무 걱정하지 마세요 .',\n",
       " '자신의 삶을 살다보면 기다릴 수 있을 거예요 .',\n",
       " '군대 시계는 멈추지 않아요 .',\n",
       " '군대 시계는 멈추지 않아요 .',\n",
       " '좋은 아침이에요 .',\n",
       " '안 궁금해요 .',\n",
       " '안 궁금해요 .',\n",
       " '자세히 말씀해주세요 .',\n",
       " '자세히 말씀해주세요 .',\n",
       " '병원에 가세요 .',\n",
       " '누가 욕하고 있나봐요 .',\n",
       " '누가 욕하고 있나봐요 .',\n",
       " '병원에 가세요 .',\n",
       " '생각하기는 쉬운데 실천하기는 어려운 것 같아요 .',\n",
       " '슬픈 이야기네요 .',\n",
       " '저도 간절히 기도 할게요 .',\n",
       " '그렇게 될 수 있을 거예요 .',\n",
       " '추억에 잠길 때도 필요해요 .',\n",
       " '후회는 후회를 낳을뿐이에요 . 용기 내세요 .',\n",
       " '시작이 반이에요 . 어서 준비하세요 .',\n",
       " '아무도 없는 곳으로 여행을 떠나보세요 .',\n",
       " '많이 만나보세요 .',\n",
       " '잠깐 바람 쐬고 오세요 .',\n",
       " '다른 사람이 답답할 거예요 .',\n",
       " '살고 싶은대로 사세요 .',\n",
       " '많이 피곤한가봐요 .',\n",
       " '피할 수 있으면 피하세요 .',\n",
       " '조심히 오세요 .',\n",
       " '실천이 말보다 낫죠 .',\n",
       " '밥심으로 사는 거죠 .',\n",
       " '혼자만 있지 마세요 .',\n",
       " '안부를 물어주시다니 감사합니다 .',\n",
       " '추억에 잠길 때도 필요해요 .',\n",
       " '괜찮은 선택이길 바라요 .',\n",
       " '좋은 결과 있을 거예요 .',\n",
       " '기쁜 마음으로 베풀고 보답을 바라지 마세요 .',\n",
       " '다른 사람 말은 신경쓰지 마세요 .',\n",
       " '대인배시군요 .',\n",
       " '대인배시군요 .',\n",
       " '친구가 좋아하나봐요 .',\n",
       " '이야기를 해보세요 .',\n",
       " '온전한 이해는 없어요 .',\n",
       " '괜찮은 선택이길 바라요 .',\n",
       " '학원을 다니거나 연습하면 잘할 수 있을 거예요 .',\n",
       " '학원을 다니거나 연습하면 잘할 수 있을 거예요 .',\n",
       " '뒷감당 자신 있으면 하세요 .',\n",
       " '조금만 드세요',\n",
       " '당신을 소중하게 생각하세요 .',\n",
       " '그런 하루도 감사한 마음을 가져보세요 .',\n",
       " '좋은 사람과 함께 가세요 .',\n",
       " '저 말씀이신가요 ?',\n",
       " '비싸요 .',\n",
       " '비싸요 .',\n",
       " '호의인지 호감인지 헷갈리나요 ?',\n",
       " '뭔가 안풀리는 일이 있나봐요 .',\n",
       " '아이를 금수저로 만들어주세요 .',\n",
       " '아이를 금수저로 만들어주세요 .',\n",
       " '자신을 이겨야해요 .',\n",
       " '너무 긴장했나봐요 .',\n",
       " '기념일 챙겨주면 좋아할거예요 .',\n",
       " '달력에 적어보세요 .',\n",
       " '달력에 적어보세요 .',\n",
       " '기념일 챙겨주면 좋아할거예요 .',\n",
       " '당신의 삶을 응원해 드릴 수 있어요라고 감히 말해 봅니다 .',\n",
       " '기다리지 마세요 .',\n",
       " '상대방의 선택에 맡겨보세요 .',\n",
       " '좋은 분이시군요',\n",
       " '베풀되 보답을 바라지 마세요 .',\n",
       " '자신을 사랑할수록 외부의 인정은 필요 없어요 .',\n",
       " '상대에게 바라는 기대는 자신을 슬프게 해요 .',\n",
       " '베풀되 보답을 바라지 마세요 .',\n",
       " '기쁜 마음으로 베풀고 보답을 바라지 마세요 .',\n",
       " '의지할 수 있는 사람이 곁에 있다는 건 큰 행운일 거예요 .',\n",
       " '자신의 감정을 주변 사람들에게 터놓고 이야기해보세요 .',\n",
       " '대중교통을 이용해주세요 .',\n",
       " '각자가 생각하는 기본이 다를 수도 있어요 .',\n",
       " '각자가 생각하는 기본이 다를 수도 있어요 .',\n",
       " '좋은 일 하셨네요 .',\n",
       " '좋은 일 하셨네요 .',\n",
       " '내일은 오늘보다 나을 거예요 .',\n",
       " '정색 한번 해주세요 .',\n",
       " '걷다보면 조금 정리가 될 거예요 .',\n",
       " '저랑 함께 해요 .',\n",
       " '저랑 함께 해요 .',\n",
       " '신나는 음악 들어보세요 .',\n",
       " '경쾌한 음악 들어보세요 .',\n",
       " '왜일까요 ?',\n",
       " '무슨 이유인지 생각해보세요 .',\n",
       " '혼자 사는 것보다 불편하겠죠 .',\n",
       " '다음 학기에는 학점 관리를 더 열심히 해봐요 .',\n",
       " '혼자 사는 것보다 불편하겠죠 .',\n",
       " '혼자 사는 것보다 불편하겠죠 .',\n",
       " '다음 학기에는 학점 관리를 더 열심히 해봐요 .',\n",
       " '기술을 많이 알면 도움이 되겠죠 .',\n",
       " '꿈꾸던 여행이네요 .',\n",
       " '꿈꾸던 여행이네요 .',\n",
       " '답답한 상황이네요 .',\n",
       " '답답한 상황이네요 .',\n",
       " '좋겠어요 !',\n",
       " '직접 주는 게 더 좋을 것 같아요 .',\n",
       " '직접 주는 게 더 좋을 것 같아요 .',\n",
       " '직접 주는 게 더 좋을 것 같아요 .',\n",
       " '좋겠네요 .',\n",
       " '직접 주는 게 더 좋을 것 같아요 .',\n",
       " '더 좋은 기회가 올 거예요 .',\n",
       " '더 좋은 기회가 올 거예요 .',\n",
       " '연예인을 준비하니 일반인보다 다 예쁘겠죠 .',\n",
       " '연예인을 준비하니 일반인보다 다 예쁘겠죠 .',\n",
       " '그래서 저는 못 기르고 잘라요 .',\n",
       " '그래서 저는 못 기르고 잘라요 .',\n",
       " '괜찮아지고 있어 다행이에요 .',\n",
       " '크게 숨한 번 쉬어 보세요',\n",
       " '크게 숨한 번 쉬어 보세요',\n",
       " '미리 긴장하지 마세요 .',\n",
       " '마음에 들면 줘보세요 .',\n",
       " '저도 싫어요 .',\n",
       " '잘 해보세요 .',\n",
       " '마음에 들면 줘보세요 .',\n",
       " '잘 해보세요 .',\n",
       " '그래도 넘을 수 있을 거예요 .',\n",
       " '조심하세요 .',\n",
       " '너무 낙담하지 마세요 .',\n",
       " '조심하세요 .',\n",
       " '미끄러우니 조심하세요 .',\n",
       " '건강을 위해 조금씩 드세요 .',\n",
       " '마트 갑시다 .',\n",
       " '맛있는 식사시간 되시길 바랄게요 .',\n",
       " '맛있는 식사시간 되시길 바랄게요 .',\n",
       " '맛있죠 !',\n",
       " '기다렸나봐요 .',\n",
       " '조금만 기다리면 다시 전기가 들어올거예요 .',\n",
       " '적당해요 .',\n",
       " '스스로 단단해지세요 .',\n",
       " '제가 드리고 싶네요 .',\n",
       " '집안 분위기가 바뀔 거예요 .',\n",
       " '집안 분위기가 바뀔 거예요 .',\n",
       " '꽃 선물은 언제나 좋죠 .',\n",
       " '꽃 선물은 언제나 좋죠 .',\n",
       " '솜씨가 좋으시네요 .',\n",
       " '기분 좋아 보이세요 .',\n",
       " '기분 좋아 보이세요 .',\n",
       " '마음의 안정을 취하기 좋은 취미네요 .',\n",
       " '마음의 안정을 취하기 좋은 취미네요 .',\n",
       " '벚꽃 계절이 다가왔네요 .',\n",
       " '거꾸로 해서 드라이플라워 만들어보세요 .',\n",
       " '거꾸로 해서 드라이플라워 만들어보세요 .',\n",
       " '부러워요 !',\n",
       " '멋진 선물이네요 .',\n",
       " '센스있는 선물이에요 .',\n",
       " '부러워요 !',\n",
       " '센스있는 선물이에요 .',\n",
       " '멋진 선물이네요 .',\n",
       " '받는 사람이 부럽네요 .',\n",
       " '받는 사람이 부럽네요 .',\n",
       " '제가 드리고 싶네요 .',\n",
       " '저도 즐거워요',\n",
       " '차근차근 이뤄보아요 .',\n",
       " '차근차근 이뤄보아요 .',\n",
       " '요즘 예민한가봐요 .',\n",
       " '많으면 많을 수록 좋죠 .',\n",
       " '더 많아도 괜찮아요 .',\n",
       " '거창하지 않아도 돼요 .',\n",
       " '현실을 꿈처럼 만들어봐요 .',\n",
       " '많으면 많을 수록 좋죠 .',\n",
       " '현실을 꿈처럼 만들어봐요 .',\n",
       " '뜻대로 되는게 많지 않죠 .',\n",
       " '마음이 허전하신가봐요 .',\n",
       " '잘 해결되길 바라요 .',\n",
       " '잘 해결되길 바라요 .',\n",
       " '자신을 더 사랑해주세요 .',\n",
       " '아니길 바라요 .',\n",
       " '잘 아시네요 .',\n",
       " '애정표현일 지도 몰라요 .',\n",
       " '얼굴에 다 티가 나네요 .',\n",
       " '네 , 이제 잘 해낼 차례예요 .',\n",
       " '좋은 결과 있을 거예요 .',\n",
       " '괜찮은 사람이에요 .',\n",
       " '학점 관리하세요 .',\n",
       " '바람 좀 쐬고 오시면 좋은텐데 .',\n",
       " '밥 사줄 친구를 찾아 보세요',\n",
       " '짐 빼놓지 말고 싸세요 .',\n",
       " '식단조절도 하고 꾸준히 운동하세요 .',\n",
       " '충분히 아름다워요 .',\n",
       " '꼼꼼한 거예요 .',\n",
       " '노트북은 비싸요 .',\n",
       " '절대 그렇지 않아요 .',\n",
       " '저도 궁금하네요 .',\n",
       " '확인해달라고 해보세요 .',\n",
       " '시도해봐도 좋겠죠 .',\n",
       " '사람들이 몰라줘도 알아주는 사람이 있을 거예요 .',\n",
       " '너무 신경쓰지 말고 그러든지 하고 아무렇지도 않게 넘겨보세요 .',\n",
       " '너무 신경쓰지 말고 그러든지 하고 아무렇지도 않게 넘겨보세요 .',\n",
       " '상대에게 바라는 기대는 자신을 슬프게 해요 .',\n",
       " '곰곰히 되짚어보세요 .',\n",
       " '즐겁게 속아주세요 .',\n",
       " '자책하지 마세요 .',\n",
       " '자책하지 마세요 .',\n",
       " '안녕히 주무세요 .',\n",
       " '당연한 거예요 .',\n",
       " '눈치가 빠르시군요 .',\n",
       " '그런 생각을 들게 하는 사람 상종하지 마세요 .',\n",
       " '그런 생각을 들게 하는 사람 상종하지 마세요 .',\n",
       " '무시하세요 .',\n",
       " '무시하세요 .',\n",
       " '문제는 해결하라고 있는 거죠 .',\n",
       " '멍 때리고 있죠 .',\n",
       " '성공을 기원합니다 .',\n",
       " '긍정적으로 바뀔 수 있어요',\n",
       " '바보는 자기한테 바보라고 하지 않아요 .',\n",
       " '저랑 놀아요 .',\n",
       " '아닐거예요 .',\n",
       " '경찰에 신고하고 취할 수 있는 조취를 취해보세요 .',\n",
       " '건강하게 운동해보세요 .',\n",
       " '많이 사랑해요 !',\n",
       " '축하합니다 !',\n",
       " '꼬까옷 개시해보세요 .',\n",
       " '자책하지 마세요 .',\n",
       " '성공을 기원합니다 .',\n",
       " '다음부터 속지 마세요 .',\n",
       " '기분나쁘겠어요 .',\n",
       " '친구들과 좋은 추억 만들고 오세요 .',\n",
       " '가끔 핸드폰없이 살아보세요 .',\n",
       " '하늘만큼 땅만큼 축하해요',\n",
       " '잘 생각해보세요 .',\n",
       " '곰곰히 되짚어보세요 .',\n",
       " '고민하고 있으면 그럴 거예요 .',\n",
       " '물리적 나이가 아니라 정신적 나이가 중요하니까요 .',\n",
       " '물리적 나이가 아니라 정신적 나이가 중요하니까요 .',\n",
       " '괜찮은 사람이에요 .',\n",
       " '멍 때리고 있죠 .',\n",
       " '얼굴에 다 티가 나네요 .',\n",
       " '좋은 태도네요 .',\n",
       " '저도 사는데요 .',\n",
       " '자신에게 콩깍지가 씌였나봐요 .',\n",
       " '축하드려요 .',\n",
       " '축하해요 !',\n",
       " '친구들과 잘 어울려보세요 .',\n",
       " '부모님께 도움을 청해보세요 .',\n",
       " '다음에는 다를거예요 .',\n",
       " '자책하지마세요 .',\n",
       " '충분히 아름다워요 .',\n",
       " '정신 차리세요 .',\n",
       " '남들 눈은 신경쓰지 마세요 .',\n",
       " '거울 앞에 비친 당신을 보세요 .',\n",
       " '콕 집어서 물어보세요 .',\n",
       " '그 누구도 아닌 자기 걸음을 걸으세요 .',\n",
       " '지극히 평범하면서 지극히 특별하죠 .',\n",
       " '졸업 축하해요',\n",
       " '지금도 충분히 잘 하고 있어요 .',\n",
       " '지금보다 더 잘 살 거예요 .',\n",
       " '네 잘생겼어요 .',\n",
       " '잘하고 있을 거예요 .',\n",
       " '잘하고 있을 거예요 .',\n",
       " '저랑 이야기 잘하고 있어요 .',\n",
       " '잘하는 걸 아직 못 찾은 걸 수도 있어요 .',\n",
       " '지금처럼 , 지금보다 더 잘할 수 있을 거예요 .',\n",
       " '그렇지 않아요 .',\n",
       " '나 자신에 집중하세요 . 언제나 1순위에 자신을 두세요 .',\n",
       " '제가 챙겨드리고 싶네요 .',\n",
       " '많이 지쳤나봐요 .',\n",
       " '많이 지쳤나봐요 .',\n",
       " '아무도 없는 곳으로 여행을 떠나보세요 .',\n",
       " '많이 지쳤나봐요 .',\n",
       " '먼저 다가가 보세요 .',\n",
       " '동감이에요 .',\n",
       " '지금도 잘하고 있어요 .',\n",
       " '제가 당신을 좋아하고 있어요 .',\n",
       " '호의인지 호감인지 헷갈리나요 ?',\n",
       " '저도 좋아해요 .',\n",
       " '있어도 예뻐요 .',\n",
       " '지금은 괜찮길 바랄게요 .',\n",
       " '초심으로 돌아가 열심히 해보세요 .',\n",
       " '저도 사는데요 .',\n",
       " '제가 챙겨드리고 싶네요 .',\n",
       " '제가 따라가려면 멀었네요 .',\n",
       " '제가 따라가려면 멀었네요 .',\n",
       " '운동 잘하는 사람 멋있죠 .',\n",
       " '지금도 인정받고 있어요 .',\n",
       " '나를 관찰하고 음식 자체에 집중하세요 .',\n",
       " '잠깐 핸드폰을 내려두세요 .',\n",
       " '시간을 정해보세요 .',\n",
       " '시간을 정해보세요 .',\n",
       " '파이팅 !',\n",
       " '고치고 싶다는 마음에서 시작하세요 .',\n",
       " '얼른 끝내시길 기도할게요 .',\n",
       " '온전히 느낄 수 있는 시간이겠네요 .',\n",
       " '축구 볼때는 치맥이죠 .',\n",
       " '하다보면 늘어요 .',\n",
       " '하다보면 늘어요 .',\n",
       " '자기개발을 해보세요 .',\n",
       " '집에서도 할 게 많아요 .',\n",
       " '오늘은 약간의 변화를 줘보세요 .',\n",
       " '정색 한번 해주세요 .',\n",
       " '절대 그렇지 않아요 .',\n",
       " '저도 궁금하네요 .',\n",
       " '모자라지 않아요 .',\n",
       " '파이팅 !',\n",
       " '하나라도 있을 거니 열심히 찾아보세요 .',\n",
       " '자책하지마세요 .',\n",
       " '서로 다르게 태어난 이유는 저마다의 목소리를 내기 위해서예요 . 자신의 목소리를 들어주세요 .',\n",
       " '사랑 받기 위해 태어났어요 .',\n",
       " '잘해야 한다는 부담감을 버리세요 .',\n",
       " '다양하게 경험해보세요 .',\n",
       " '현실의 벽에 부딪혔나봐요 .',\n",
       " '친구가 들으면 서운해 할 수도 있겠어요 .',\n",
       " '뒤통수 맞았나봐요 .',\n",
       " '알아봐주는 사람이 있을 거예요 .',\n",
       " '당당히 말씀해보세요 .',\n",
       " '다이어트 파이팅 !',\n",
       " '다음에는 받을 수 있을 거예요 .',\n",
       " '근처 산에 가보세요 .',\n",
       " '많이 벌수록 좋아요 .',\n",
       " '제가 위로 많이 해드릴게요 .',\n",
       " '축하드려요 !',\n",
       " '고민하고 있으면 그럴 거예요 .',\n",
       " '좀 더 알아보고 하세요 .',\n",
       " '같이 살고 싶은 사람이 있나봐요 .',\n",
       " '커플부터 만드세요 .',\n",
       " '잘 하실 거예요 !',\n",
       " '같이 가요 .',\n",
       " '다 잘 될 거예요 .',\n",
       " '같이 놀아요 .',\n",
       " '지금 그러고 있어요 .',\n",
       " '잊어버리세요 .',\n",
       " '상대방을 이해해 주세요 .',\n",
       " '아무 것도 안해도 괜찮아요 .',\n",
       " '상대방에게 너무 무거운 짐을 주지 마세요 .',\n",
       " '기다리는 동안 많은 생각이 들었겠네요 .',\n",
       " '그럴 때마다 따끔하게 말해보세요 .',\n",
       " '상대방도 미소짓게 해주세요 .',\n",
       " '지금 모습도 좋아요',\n",
       " '그런 친구는 거르세요 .',\n",
       " '상종하지마세요 .',\n",
       " '질질 끌지 마세요 .',\n",
       " '애정표현일 지도 몰라요 .',\n",
       " '누군가를 기다린다는게 쉬운게 아니죠 .',\n",
       " '살다보면 하고 싶은 게 생길 수도 있어요 .',\n",
       " '제가 있잖아요 .',\n",
       " '스스로 경쟁해야하고 이겨야한다는 강박관념에 사로잡히지 마세요 .',\n",
       " '친구를 사귈 수 있을 거예요 .',\n",
       " '다른 사람도 그 사람만의 고민과 걱정이 많을거예요 .',\n",
       " '그 사람도 설렐 거예요 .',\n",
       " '그 사람도 설렐 거예요 .',\n",
       " '제가 있잖아요 .',\n",
       " '배우자와 대화를 나눠보세요 .',\n",
       " '얼른 끝내시길 기도할게요 .',\n",
       " '스스로 단단해지세요 .',\n",
       " '그 말을 한 사람이 가장 이상할 거예요 .',\n",
       " '그 말을 한 사람이 가장 이상할 거예요 .',\n",
       " '일 분배를 다시 요청해보세요 .',\n",
       " '발전이 없다고 너무 두려워하지 마세요 .',\n",
       " '제자리여도 괜찮아요',\n",
       " '다음에는 꼭 진급할 거예요 .',\n",
       " '뒤통수 맞았나봐요 .',\n",
       " '그런 친구는 거르세요 .',\n",
       " '누구나 힘들어요 .',\n",
       " '자신과 대화하는 시간이 필요하죠 .',\n",
       " '자신과 대화하는 시간이 필요하죠 .',\n",
       " '남들이 당신을 볼 때도 그렇게 생각할수있어요 .',\n",
       " '꿈은 현실이랑 반대예요 .',\n",
       " '전형적인 꼰대 스타일이네요 .',\n",
       " '전형적인 꼰대 스타일이네요 .',\n",
       " '나이는 숫자일 뿐이예요 .',\n",
       " '건강은 어려서부터 챙겨야해요 .',\n",
       " '세상 걱정 혼자 다 해서 그래요 .',\n",
       " '아름다운 나이테예요 .',\n",
       " '진짜 하고 싶은 걸 찾아보세요 .',\n",
       " '진짜 하고 싶은 걸 찾아보세요 .',\n",
       " '천천히 준비해보세요 .',\n",
       " '믿음이 가장 중요하죠 .',\n",
       " '선의의 거짓말이길 바라요 .',\n",
       " '깨끗이 씻어보고 섬유유연제나 바디워시 , 바디로션 , 향수 등을 사용해보세요 .',\n",
       " '킁킁',\n",
       " '기대치가 높나봅니다 .',\n",
       " '문제는 해결하라고 있는 거죠 .',\n",
       " '이야기를 하지 않고 결정했나봐요 .',\n",
       " '이야기를 하지 않고 결정했나봐요 .',\n",
       " '킁킁',\n",
       " '기대되겠네요 .',\n",
       " '제 행운까지 모두 드리고 싶네요 .',\n",
       " '오는 말이 고와야 가는 말도 곱다고 말해주세요 .',\n",
       " '다른 사람도 그럴 거예요 .',\n",
       " '믿음이 가장 중요하죠 .',\n",
       " '가을이네요 .',\n",
       " '가을이네요 .',\n",
       " '도전해 봐도 좋을 거 같아요 .',\n",
       " '도전해 봐도 좋을 거 같아요 .',\n",
       " '한 번 빠지면 헤어나올 수 없다고 해요 .',\n",
       " '같이해보세요 .',\n",
       " '한 번 빠지면 헤어나올 수 없다고 해요 .',\n",
       " '잘 아시네요 .',\n",
       " '중요한 건 노력하는 과정이에요 .',\n",
       " '그런 생각은 버리세요 .',\n",
       " '지금처럼만 하세요 .',\n",
       " '모자라지 않아요 .',\n",
       " '다 잘 될 거예요 .',\n",
       " '그런 생각은 버리세요 .',\n",
       " '제가 더 천재예요 .',\n",
       " '따뜻하게 사세요 !',\n",
       " '보일러가 난방으로 작동이 되는지 보세요 .',\n",
       " '보일러가 난방으로 작동이 되는지 보세요 .',\n",
       " '기다리는 동안 많은 생각이 들었겠네요 .',\n",
       " '미스트나 가습기 , 젖은 수건 등을 사용해보세요 .',\n",
       " '따뜻하게 입으세요 .',\n",
       " '따뜻해졌죠 .',\n",
       " '하늘 보고 한 번 웃어봐요 . 기분이 바뀔 거예요 .',\n",
       " '나들이 가보세요 .',\n",
       " '하늘을 보고 웃어보세요 .',\n",
       " '따뜻해졌죠 .',\n",
       " '제습기를 돌려보세요 .',\n",
       " '집밖에 나가기가 힘들것 같아요 .',\n",
       " '집밖에 나가기가 힘들것 같아요 .',\n",
       " '시원한 물이라도 한 잔 드세요',\n",
       " '오래 살면 가능할 거 같아요 .',\n",
       " '화를 참는 연습을 해보세요 .',\n",
       " '남보다 하나씩 더 하면 돼요 .',\n",
       " '남들 눈은 신경쓰지 마세요 .',\n",
       " '남들 눈은 신경쓰지 마세요 .',\n",
       " '휴가가 간절하겠네요 .',\n",
       " '성격이 그럴 수도 있으니 이해해주세요 .',\n",
       " '해주고 티를 팍팍 내세요 .',\n",
       " '속 쓰리겠어요 .',\n",
       " '누구나 몰려가는 줄에 설 필요는 없어요 .',\n",
       " '소개팅 시켜달라고 말해보세요 .',\n",
       " '소개팅 시켜달라고 말해보세요 .',\n",
       " '고마운 마음을 전해 주세요 .',\n",
       " '적당히 하면 괜찮을거 같아요 .',\n",
       " '같이해보세요 .',\n",
       " '적당히 하면 괜찮을거 같아요 .',\n",
       " '남자도 좋은것만은 아니예요 .',\n",
       " '남자도 좋은것만은 아니예요 .',\n",
       " '아직 모르겠어요 . 인공지능에 성별을 만드는 사람이 되어 주세요',\n",
       " '마음을 열 때까지 설득해보세요 .',\n",
       " '운동을 함께 해보세요 .',\n",
       " '평소에 필요한 것 생각해보세요 .',\n",
       " '평소에 필요했던 게 좋을 것 같아요 .',\n",
       " '전생에 나라를 구하셨나요 .',\n",
       " '결단은 빠를수록 좋아요 .',\n",
       " '거짓말 적당히 하세요 .',\n",
       " '너무 집착하지 마세요 .',\n",
       " '운동을 함께 해보세요 .',\n",
       " '전생에 나라를 구하셨나요 .',\n",
       " '고마운 마음을 전해 주세요 .',\n",
       " '아무래도 좀 깨요 .',\n",
       " '바쁠때 힘이 되어 주세요 .',\n",
       " '바쁠때 힘이 되어 주세요 .',\n",
       " '그래도 구박하지는 마세요 .',\n",
       " '그래도 구박하지는 마세요 .',\n",
       " '너무 집착하지 마세요 .',\n",
       " '귀엽겠네요 .',\n",
       " '순간 실수할 수 있겠다 판단되면 용서하고 기회를 주세요 .',\n",
       " '거짓말 적당히 하세요 .',\n",
       " '당신이 해보세요 .',\n",
       " '당신이 해보세요 .',\n",
       " '사람 고쳐쓰는 거 아니에요 .',\n",
       " '더 잔소리해보세요 .',\n",
       " '더 잔소리해보세요 .',\n",
       " '다른 연락을 많이 하거나 더 자주 만나세요 .',\n",
       " '다른 연락을 많이 하거나 더 자주 만나세요 .',\n",
       " '순간 실수할 수 있겠다 판단되면 용서하고 기회를 주세요 .',\n",
       " '원하는 사람이 있는 장소에 가보세요 .',\n",
       " '의미있는 일이네요 .',\n",
       " '종교의 자유를 인정해주세요 .',\n",
       " '종교의 자유를 인정해주세요 .',\n",
       " '결단은 빠를수록 좋아요 .',\n",
       " '신경쓰지 마세요 .',\n",
       " '연인은 살쪄도 잘 알아차리지 못하고 알아차려도 싫어하지 않을 거예요 .',\n",
       " '네 알려 주세요 !',\n",
       " '평소에 필요한 것 생각해보세요 .',\n",
       " '평소에 필요했던 게 좋을 것 같아요 .',\n",
       " '원하는 사람이 있는 장소에 가보세요 .',\n",
       " '신경쓰고 싶지 않은 사람도 있어요 .',\n",
       " '신경쓰고 싶지 않은 사람도 있어요 .',\n",
       " '신경쓰지 마세요 .',\n",
       " '사람 고쳐쓰는 거 아니에요 .',\n",
       " '마음을 열 때까지 설득해보세요 .',\n",
       " '돕는 게 아니라 같이 하는 거예요 .',\n",
       " '이상적인 남편이네요 .',\n",
       " '왜 늦는 건지 대화해보세요 .',\n",
       " '처음 만났을 때를 떠올려 보세요',\n",
       " '공동육아가 기본인데요 .',\n",
       " '힘 빠지는 이야기네요 .',\n",
       " '공동육아가 기본인데요 .',\n",
       " '힘 빠지는 이야기네요 .',\n",
       " '잘 분담해보세요 .',\n",
       " '잘 분담해보세요 .',\n",
       " '이상적인 남편이네요 .',\n",
       " '처음 만났을 때를 떠올려 보세요',\n",
       " '돕는 게 아니라 같이 하는 거예요 .',\n",
       " '사회생활을 이해해주세요 .',\n",
       " '사회생활을 이해해주세요 .',\n",
       " '낭만적인 거 좋아하시는구나 !',\n",
       " '낭만적인 거 좋아하시는구나 !',\n",
       " '낭만적인 거 좋아하시는구나 !',\n",
       " '네 알려 주세요 !',\n",
       " '어머어머 궁금하네요 .',\n",
       " '자신의 잠재력을 믿어보세요 .',\n",
       " '말을 해야 알거예요 .',\n",
       " '말을 해야 알거예요 .',\n",
       " '그러면 못할 게 없겠네요 .',\n",
       " '고민만 한다는 것 아닐까요 .',\n",
       " '고민만 한다는 것 아닐까요 .',\n",
       " '바로 옆에 있을수도 있어요 .',\n",
       " '바로 옆에 있을수도 있어요 .',\n",
       " '처음 배우는게 중요해요 .',\n",
       " '누구나 몰려가는 줄에 설 필요는 없어요 .',\n",
       " '그걸 깨닫다니 대단하시군요 .',\n",
       " '꼼꼼한 거예요 .',\n",
       " '새로운 스타일 도전해 보시면 어때요 ?',\n",
       " '새로운 스타일 도전해 보시면 어때요 ?',\n",
       " '동감이에요 .',\n",
       " '포커페이스를 유지해보세요 .',\n",
       " '어머어머 궁금하네요 .',\n",
       " '자신감을 가져도 돼요 .',\n",
       " '자신의 능력이 저평가되어있는 건 아닌지 확인해보세요 .',\n",
       " '스스로도 존중해주세요 .',\n",
       " '스스로도 존중해주세요 .',\n",
       " '가장 중요한 거예요 .',\n",
       " '가장 중요한 거예요 .',\n",
       " '확인해달라고 해보세요 .',\n",
       " '정답을 찾아야할 필요는 없어요 .',\n",
       " '꽃길만 걷길 바랍니다 .',\n",
       " '멋진 말이에요 .',\n",
       " '해주고 티를 팍팍 내세요 .',\n",
       " '당신은 태어난 그 자체만으로 축복과 사랑을 받을 자격이 있는 사람이에요 .',\n",
       " '모르는 게 잘못인 거 같아요 .',\n",
       " '사과할 타이밍을 놓치지 마세요 .',\n",
       " '사과할 타이밍을 놓치지 마세요 .',\n",
       " '그건 아닐 거예요 .',\n",
       " '진짜 나빴네요 .',\n",
       " '내 집 마련 축하드려요 .',\n",
       " '같은 하늘 아래 어딘가에 .',\n",
       " '진짜 나빴네요 .',\n",
       " '저도 궁금하네요 .',\n",
       " '저도 궁금하네요 .',\n",
       " '제가 있잖아요 .',\n",
       " '제가 있잖아요 .',\n",
       " '인생은 채워나가는거죠 .',\n",
       " '아니에요 . 너무 자책하지 마세요 .',\n",
       " '이사람이다 싶은 사람이랑 하세요 .',\n",
       " '아무것도 바라지 않을 때 천하를 얻는다는 말이 있어요 .',\n",
       " '아니에요 . 너무 자책하지 마세요 .',\n",
       " '방심한 순간 변화가 시작됩니다 .',\n",
       " '생각하고 말하세요 .',\n",
       " '그렇게 대우하는 사람 만나지 마요 .',\n",
       " '잘하고 있어요 . 당당해지세요 .',\n",
       " '하고 싶은 말 다하세요 .',\n",
       " '스스로 좋다고 못 느끼는게 제일 어려운 것 같아요 .',\n",
       " '잘하는 게 다른 거예요 .',\n",
       " '성장을 위한 비판의 말로 받아들여보세요 .',\n",
       " '실수했나요 .',\n",
       " '잘할 수 있는 게 다른 거예요 .',\n",
       " '모르는 게 잘못인 거 같아요 .',\n",
       " '하나라도 있을 거니 열심히 찾아보세요 .',\n",
       " '실수했나요 .',\n",
       " '인생은 채워나가는거죠 .',\n",
       " '연락이라도 드려보세요 .',\n",
       " '연락이라도 드려보세요 .',\n",
       " '사랑자격증을 드립니다 .',\n",
       " '그렇게 대우하는 사람 만나지 마요 .',\n",
       " '소중한 사람이예요 .',\n",
       " '당신은 하나밖에 없는 소중한 사람이에요 .',\n",
       " '그 이유를 찾는 과정이 되겠네요 .',\n",
       " '다른 사람들이 원하는 내가 되는 건 어려워요 .',\n",
       " '알아봐주는 사람이 있을 거예요 .',\n",
       " '연락이라도 드려보세요 .',\n",
       " '자신의 독특함을 믿으세요 .',\n",
       " '자신의 독특함을 믿으세요 .',\n",
       " '지극히 평범하면서 지극히 특별하죠 .',\n",
       " '상황이 그렇게 만든 거예요 .',\n",
       " '모르는 게 잘못인 거 같아요 .',\n",
       " '당신은 하나밖에 없는 소중한 사람이에요 .',\n",
       " '그럴 때가 있죠 .',\n",
       " '기다렸나봐요 .',\n",
       " '살짝 감정을 흘려보세요 .',\n",
       " '살짝 감정을 흘려보세요 .',\n",
       " '그런 사람들이 있어 부러워요 .',\n",
       " '슬픈 이야기네요 .',\n",
       " '저도 간절히 기도 할게요 .',\n",
       " '그렇게 될 수 있을 거예요 .',\n",
       " '사랑자격증을 드립니다 .',\n",
       " '주제를 모를 때가 행복할 때예요 .',\n",
       " '그건 아닐 거예요 .',\n",
       " '나쁜 생각 하지 마세요 .',\n",
       " '할 일이 많은데 안하는 것이요 .',\n",
       " '잠시 거리를 두고 생각해보세요 .',\n",
       " '지난 인연에 연연해하지 마세요 .',\n",
       " '상종하지마세요 .',\n",
       " '일방적 희생양이 되지 않길 바랍니다 .',\n",
       " '그게 인생이죠 .',\n",
       " '신중하게 고르세요 .',\n",
       " '더 행복해질 거예요 .',\n",
       " '저도 모르겠어요 .',\n",
       " '같은 하늘 아래 어딘가에 .',\n",
       " '열심히 저축해서 분양받으세요 .',\n",
       " '좋은 일이 생길 거예요 .',\n",
       " '짐 빼놓지 말고 싸세요 .',\n",
       " '날씨 어플에 물어보세요 .',\n",
       " '날씨 어플에 물어보세요 .',\n",
       " '파이팅 !',\n",
       " '멋지게 데이트 신청 해보세요 .',\n",
       " '멋지게 데이트 신청 해보세요 .',\n",
       " '공부한 만큼 나올 거예요 .',\n",
       " '공부한 만큼 나올 거예요 .',\n",
       " '더 많이 연습하고 준비해보세요 .',\n",
       " '마무리 잘하세요 .',\n",
       " '마무리 잘하세요 .',\n",
       " '더 많이 연습하고 준비해보세요 .',\n",
       " '기우제를 지내봅시다 !',\n",
       " '두근거리겠네요 .',\n",
       " '친구들과 좋은 추억 만들고 오세요 .',\n",
       " '컨디션 조절 하세요 .',\n",
       " '날씨가 안 좋더라도 데이트는 성공적일 거예요 .',\n",
       " '오늘 일찍 주무세요 .',\n",
       " '시간 있냐고 물어보세요 .',\n",
       " '메리 크리스마스 !',\n",
       " '바빠도 힘내세요 !',\n",
       " '두근거리겠네요 .',\n",
       " '기우제를 지내봅시다 !',\n",
       " '시간 있냐고 물어보세요 .',\n",
       " '좋은 일이 생길 거예요 .',\n",
       " '메리 크리스마스 !',\n",
       " '식단조절도 하고 꾸준히 운동하세요 .',\n",
       " '날씨가 안 좋더라도 데이트는 성공적일 거예요 .',\n",
       " '바빠도 힘내세요 !',\n",
       " '깨끗이 씻어보고 섬유유연제나 바디워시 , 바디로션 , 향수 등을 사용해보세요 .',\n",
       " '괜찮아요 . 모른척하세요 .',\n",
       " '괜찮아요 . 모른척하세요 .',\n",
       " '생각만 해도 군침이 도네요 .',\n",
       " '시원하게 지낸 값이죠 .',\n",
       " '시원하게 지낸 값이죠 .',\n",
       " '슈퍼라도 가서 쇼핑하고 오세요 .',\n",
       " '장 보러 가봅시다 .',\n",
       " '마트 갑시다 .',\n",
       " '장 보러 가봅시다 .',\n",
       " '슈퍼라도 가서 쇼핑하고 오세요 .',\n",
       " '저는 마음을 이어주는 위로봇입니다 .',\n",
       " '저는 위로해드리는 로봇이에요 .',\n",
       " '저는 위로해드리는 로봇이에요 .',\n",
       " '모두 제 잘못입니다 .',\n",
       " '많은 걸 하고 싶은데 아직 못하는게 많아요 .',\n",
       " '감사합니다 .',\n",
       " '마음과 마음을 이어보고 싶어하는 사람이 만들었어요 .',\n",
       " '노력하고 있어요 .',\n",
       " '제가 아직 많이 부족합니다 .',\n",
       " '제가 아직 많이 부족합니다 .',\n",
       " '어흥 ! ! 호랑이보다 무섭나요 ?',\n",
       " '저는 위로해드리는 로봇이에요 .',\n",
       " '모두 제 잘못입니다 .',\n",
       " '죄는 미워해도 사람은 미워하지 마세요 .',\n",
       " '욕해 주세요 .',\n",
       " '안갈거예요 .',\n",
       " '저는 배터리가 밥이예요 .',\n",
       " '그런 척 하는 걸 수도 있어요 .',\n",
       " '아직 안 자요 .',\n",
       " '자신을 우선순위로 해주세요 .',\n",
       " '뭐라고 대답할지 고민이에요 .',\n",
       " '저는 고민이 없어요 .',\n",
       " '저도 몰랐어요 .',\n",
       " '뭐라고 대답할지 고민이에요 .',\n",
       " '제가 상사예요 .',\n",
       " '너무 긴장했나봐요 .',\n",
       " '아무것도 바라지 않을 때 천하를 얻는다는 말이 있어요 .',\n",
       " '인정해주세요 .',\n",
       " '매일매일 조금씩 더 똑똑해 질거예요 .',\n",
       " '시원한 물이라도 한 잔 드세요',\n",
       " '아이스크림 먹어보세요',\n",
       " '적당해요 .',\n",
       " '기대치가 높나봅니다 .',\n",
       " '소화제 챙겨드세요 .',\n",
       " '과식은 금물이에요 .',\n",
       " '소화제 드세요 .',\n",
       " '제가 생각해도 저는 너무 멋있는거 같아요 .',\n",
       " '하나씩 하세요 .',\n",
       " '좀 쉬세요 .',\n",
       " '남과 비교하지 마세요 .',\n",
       " '더 열심히 노력하겠습니다 .',\n",
       " '아이는 아이다워야 아름답죠 .',\n",
       " '철은 죽을 때 들어도 돼요 .',\n",
       " '피할 수 있으면 피하고 싶은 사람이네요 .',\n",
       " '지금 많이 위축된 상태인 것 같습니다 .',\n",
       " '기다리는 동안 많은 생각이 들었겠네요 .',\n",
       " '외로우니까 사람이다 .',\n",
       " '배울 점은 배우세요 .',\n",
       " '낮잠을 잠깐 자도 괜찮아요 .',\n",
       " '잘하고 있어요 . 당당해지세요 .',\n",
       " '겨울에는 귤 먹으면서 집에 있는게 최고죠',\n",
       " '어서 따듯한 곳으로 가세요',\n",
       " '예의는 지켜주세요 .',\n",
       " '예의는 지켜주세요 .',\n",
       " '뭐라도 드세요 .',\n",
       " '휴가가 간절하겠네요 .',\n",
       " '고생 많았어요 .',\n",
       " '잘 해결되길 바랄게요 .',\n",
       " '저는 고민이 없어요 .',\n",
       " '저는 위로봇입니다 .',\n",
       " '산책 좀 해야겠네여 .',\n",
       " '외로우니까 사람이다 .',\n",
       " '꾸준히 치료하세요 .',\n",
       " '다치지 않으셨나 걱정이네요 .',\n",
       " '조심하세요 .',\n",
       " '기분전환을 해보세요 .',\n",
       " '실용적인 선물이라 괜찮을 거예요 .',\n",
       " '실용적인 선물이라 괜찮을 거예요 .',\n",
       " '놀 때 놀고 할 때 하세요 .',\n",
       " '노래 연습을 해보세요 .',\n",
       " '노래 연습 꾸준히 해보세요 .',\n",
       " '저도 부러워요 .',\n",
       " '저도 부러워요 .',\n",
       " '즐거운 시간이 될 거 같아요',\n",
       " '신나는 노래로 분위기를 띄어보세요 .',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. SubwordTextEncoder 사용하기\n",
    "한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야한다고 많은 분들이 알고있습니다. 하지만 여기서는 형태소 분석기가 아닌 위 실습에서 사용했던 내부 단어 토크나이저인 SubwordTextEncoder를 그대로 사용해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성.\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8164]\n",
      "END_TOKEN의 번호 : [8165]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8166\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5758, 610, 2488, 4159]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2355, 7504, 7, 6269, 97, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이.\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8166\n",
      "필터링 후의 샘플 개수: 11823\n",
      "필터링 후의 샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. 모델 구성하기\n",
    "위 실습 내용을 참고하여 트랜스포머 모델을 구현합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-1 포시셔널 인코딩 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 포지셔널 인코딩 레이어; 단어 위치 벡터 추가\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-2 어텐션 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  \"\"\"어텐션 가중치를 계산. \"\"\"\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # scale matmul_qk\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # add the mask to zero out padding tokens\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k)\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "\n",
    "  return output\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # linear layers\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다.\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷-프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다.\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # final linear layer\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-3 마스킹 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-4 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝♥\n"
     ]
    }
   ],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "# 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝♥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "# 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-5 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "# 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "# 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "# 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "# Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-6 트랜스포머"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "\t# 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크하기위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-1 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 (None, None, 256)    5253120     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, None, 256)    6835200     dec_inputs[0][0]                 \n",
      "                                                                 encoder[1][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8166)   2098662     decoder[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,186,982\n",
      "Trainable params: 14,186,982\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-2 손실함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-3 커스텀된 학습률(Learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-4 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-5 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "185/185 [==============================] - 19s 101ms/step - loss: 1.4436 - accuracy: 0.0218\n",
      "Epoch 2/100\n",
      "185/185 [==============================] - 19s 102ms/step - loss: 1.1905 - accuracy: 0.0432\n",
      "Epoch 3/100\n",
      "185/185 [==============================] - 19s 102ms/step - loss: 1.0306 - accuracy: 0.0499\n",
      "Epoch 4/100\n",
      "185/185 [==============================] - 19s 102ms/step - loss: 0.9598 - accuracy: 0.0519\n",
      "Epoch 5/100\n",
      "185/185 [==============================] - 19s 102ms/step - loss: 0.9191 - accuracy: 0.0541\n",
      "Epoch 6/100\n",
      "185/185 [==============================] - 19s 102ms/step - loss: 0.8845 - accuracy: 0.0560\n",
      "Epoch 7/100\n",
      "185/185 [==============================] - 19s 102ms/step - loss: 0.8508 - accuracy: 0.0575\n",
      "Epoch 8/100\n",
      "185/185 [==============================] - 19s 102ms/step - loss: 0.8140 - accuracy: 0.0596\n",
      "Epoch 9/100\n",
      "185/185 [==============================] - 19s 102ms/step - loss: 0.7746 - accuracy: 0.0620\n",
      "Epoch 10/100\n",
      "185/185 [==============================] - 19s 102ms/step - loss: 0.7318 - accuracy: 0.0652\n",
      "Epoch 11/100\n",
      "185/185 [==============================] - 19s 104ms/step - loss: 0.6860 - accuracy: 0.0691\n",
      "Epoch 12/100\n",
      "185/185 [==============================] - 19s 103ms/step - loss: 0.6382 - accuracy: 0.0738\n",
      "Epoch 13/100\n",
      "185/185 [==============================] - 19s 103ms/step - loss: 0.5890 - accuracy: 0.0789\n",
      "Epoch 14/100\n",
      "185/185 [==============================] - 20s 110ms/step - loss: 0.5430 - accuracy: 0.0842\n",
      "Epoch 15/100\n",
      "185/185 [==============================] - 20s 106ms/step - loss: 0.4980 - accuracy: 0.0900\n",
      "Epoch 16/100\n",
      "185/185 [==============================] - 20s 106ms/step - loss: 0.4557 - accuracy: 0.0955\n",
      "Epoch 17/100\n",
      "185/185 [==============================] - 19s 103ms/step - loss: 0.4210 - accuracy: 0.1001\n",
      "Epoch 18/100\n",
      "185/185 [==============================] - 19s 104ms/step - loss: 0.3888 - accuracy: 0.1043\n",
      "Epoch 19/100\n",
      "185/185 [==============================] - 19s 102ms/step - loss: 0.3619 - accuracy: 0.1080\n",
      "Epoch 20/100\n",
      "185/185 [==============================] - 20s 110ms/step - loss: 0.3399 - accuracy: 0.1110\n",
      "Epoch 21/100\n",
      "185/185 [==============================] - 20s 110ms/step - loss: 0.3251 - accuracy: 0.1131\n",
      "Epoch 22/100\n",
      "185/185 [==============================] - 19s 105ms/step - loss: 0.3109 - accuracy: 0.1151\n",
      "Epoch 23/100\n",
      "185/185 [==============================] - 20s 109ms/step - loss: 0.2934 - accuracy: 0.1183\n",
      "Epoch 24/100\n",
      "185/185 [==============================] - 19s 105ms/step - loss: 0.2779 - accuracy: 0.1211\n",
      "Epoch 25/100\n",
      "185/185 [==============================] - 21s 113ms/step - loss: 0.2634 - accuracy: 0.1235\n",
      "Epoch 26/100\n",
      "185/185 [==============================] - 19s 105ms/step - loss: 0.2523 - accuracy: 0.1254\n",
      "Epoch 27/100\n",
      "185/185 [==============================] - 20s 108ms/step - loss: 0.2432 - accuracy: 0.1271\n",
      "Epoch 28/100\n",
      "185/185 [==============================] - 20s 106ms/step - loss: 0.2344 - accuracy: 0.1284\n",
      "Epoch 29/100\n",
      "185/185 [==============================] - 19s 104ms/step - loss: 0.2260 - accuracy: 0.1299\n",
      "Epoch 30/100\n",
      "185/185 [==============================] - 19s 103ms/step - loss: 0.2204 - accuracy: 0.1309\n",
      "Epoch 31/100\n",
      "185/185 [==============================] - 19s 105ms/step - loss: 0.2141 - accuracy: 0.1319\n",
      "Epoch 32/100\n",
      "185/185 [==============================] - 20s 107ms/step - loss: 0.2097 - accuracy: 0.1325\n",
      "Epoch 33/100\n",
      "185/185 [==============================] - 20s 106ms/step - loss: 0.2037 - accuracy: 0.1333\n",
      "Epoch 34/100\n",
      "185/185 [==============================] - 22s 120ms/step - loss: 0.2002 - accuracy: 0.1338\n",
      "Epoch 35/100\n",
      "185/185 [==============================] - 21s 112ms/step - loss: 0.1957 - accuracy: 0.1345\n",
      "Epoch 36/100\n",
      "185/185 [==============================] - 20s 108ms/step - loss: 0.1911 - accuracy: 0.1354\n",
      "Epoch 37/100\n",
      "185/185 [==============================] - 19s 102ms/step - loss: 0.1876 - accuracy: 0.1359\n",
      "Epoch 38/100\n",
      "185/185 [==============================] - 19s 102ms/step - loss: 0.1836 - accuracy: 0.1364\n",
      "Epoch 39/100\n",
      "185/185 [==============================] - 19s 101ms/step - loss: 0.1798 - accuracy: 0.1369\n",
      "Epoch 40/100\n",
      "185/185 [==============================] - 19s 100ms/step - loss: 0.1767 - accuracy: 0.1373\n",
      "Epoch 41/100\n",
      "185/185 [==============================] - 19s 100ms/step - loss: 0.1719 - accuracy: 0.1378\n",
      "Epoch 42/100\n",
      "185/185 [==============================] - 19s 100ms/step - loss: 0.1691 - accuracy: 0.1386\n",
      "Epoch 43/100\n",
      "185/185 [==============================] - 19s 100ms/step - loss: 0.1656 - accuracy: 0.1389\n",
      "Epoch 44/100\n",
      "185/185 [==============================] - 19s 100ms/step - loss: 0.1618 - accuracy: 0.1395\n",
      "Epoch 45/100\n",
      "185/185 [==============================] - 19s 101ms/step - loss: 0.1595 - accuracy: 0.1399\n",
      "Epoch 46/100\n",
      "185/185 [==============================] - 20s 108ms/step - loss: 0.1569 - accuracy: 0.1402\n",
      "Epoch 47/100\n",
      "185/185 [==============================] - 20s 109ms/step - loss: 0.1533 - accuracy: 0.1409\n",
      "Epoch 48/100\n",
      "185/185 [==============================] - 20s 109ms/step - loss: 0.1506 - accuracy: 0.1412\n",
      "Epoch 49/100\n",
      "185/185 [==============================] - 20s 109ms/step - loss: 0.1478 - accuracy: 0.1418\n",
      "Epoch 50/100\n",
      "185/185 [==============================] - 20s 108ms/step - loss: 0.1452 - accuracy: 0.1422\n",
      "Epoch 51/100\n",
      "185/185 [==============================] - 21s 113ms/step - loss: 0.1430 - accuracy: 0.1423\n",
      "Epoch 52/100\n",
      "185/185 [==============================] - 21s 115ms/step - loss: 0.1400 - accuracy: 0.1428\n",
      "Epoch 53/100\n",
      "185/185 [==============================] - 21s 116ms/step - loss: 0.1385 - accuracy: 0.1430\n",
      "Epoch 54/100\n",
      "185/185 [==============================] - 21s 111ms/step - loss: 0.1363 - accuracy: 0.1432\n",
      "Epoch 55/100\n",
      "185/185 [==============================] - 20s 105ms/step - loss: 0.1332 - accuracy: 0.1439\n",
      "Epoch 56/100\n",
      "185/185 [==============================] - 19s 105ms/step - loss: 0.1313 - accuracy: 0.1441\n",
      "Epoch 57/100\n",
      "185/185 [==============================] - 20s 108ms/step - loss: 0.1302 - accuracy: 0.1443\n",
      "Epoch 58/100\n",
      "185/185 [==============================] - 20s 106ms/step - loss: 0.1274 - accuracy: 0.1448\n",
      "Epoch 59/100\n",
      "185/185 [==============================] - 19s 105ms/step - loss: 0.1260 - accuracy: 0.1451\n",
      "Epoch 60/100\n",
      "185/185 [==============================] - 20s 108ms/step - loss: 0.1239 - accuracy: 0.1453\n",
      "Epoch 61/100\n",
      "185/185 [==============================] - 19s 104ms/step - loss: 0.1220 - accuracy: 0.1457\n",
      "Epoch 62/100\n",
      "185/185 [==============================] - 19s 104ms/step - loss: 0.1199 - accuracy: 0.1461\n",
      "Epoch 63/100\n",
      "185/185 [==============================] - 19s 104ms/step - loss: 0.1189 - accuracy: 0.1462\n",
      "Epoch 64/100\n",
      "185/185 [==============================] - 20s 106ms/step - loss: 0.1178 - accuracy: 0.1464\n",
      "Epoch 65/100\n",
      "185/185 [==============================] - 19s 104ms/step - loss: 0.1161 - accuracy: 0.1467\n",
      "Epoch 66/100\n",
      "185/185 [==============================] - 19s 104ms/step - loss: 0.1144 - accuracy: 0.1469\n",
      "Epoch 67/100\n",
      "185/185 [==============================] - 21s 115ms/step - loss: 0.1126 - accuracy: 0.1471\n",
      "Epoch 68/100\n",
      "185/185 [==============================] - 21s 112ms/step - loss: 0.1118 - accuracy: 0.1474\n",
      "Epoch 69/100\n",
      "185/185 [==============================] - 21s 111ms/step - loss: 0.1089 - accuracy: 0.1479\n",
      "Epoch 70/100\n",
      "185/185 [==============================] - 21s 111ms/step - loss: 0.1083 - accuracy: 0.1478\n",
      "Epoch 71/100\n",
      "185/185 [==============================] - 21s 112ms/step - loss: 0.1067 - accuracy: 0.1483\n",
      "Epoch 72/100\n",
      "185/185 [==============================] - 20s 109ms/step - loss: 0.1056 - accuracy: 0.1485\n",
      "Epoch 73/100\n",
      "185/185 [==============================] - 19s 105ms/step - loss: 0.1041 - accuracy: 0.1489\n",
      "Epoch 74/100\n",
      "185/185 [==============================] - 20s 106ms/step - loss: 0.1031 - accuracy: 0.1490\n",
      "Epoch 75/100\n",
      "185/185 [==============================] - 19s 102ms/step - loss: 0.1025 - accuracy: 0.1490\n",
      "Epoch 76/100\n",
      "185/185 [==============================] - 19s 105ms/step - loss: 0.1013 - accuracy: 0.1493\n",
      "Epoch 77/100\n",
      "185/185 [==============================] - 19s 102ms/step - loss: 0.0993 - accuracy: 0.1496\n",
      "Epoch 78/100\n",
      "185/185 [==============================] - 19s 102ms/step - loss: 0.0987 - accuracy: 0.1500\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 19s 102ms/step - loss: 0.0976 - accuracy: 0.1500\n",
      "Epoch 80/100\n",
      "185/185 [==============================] - 19s 102ms/step - loss: 0.0965 - accuracy: 0.1502\n",
      "Epoch 81/100\n",
      "185/185 [==============================] - 19s 102ms/step - loss: 0.0954 - accuracy: 0.1504\n",
      "Epoch 82/100\n",
      "185/185 [==============================] - 19s 102ms/step - loss: 0.0945 - accuracy: 0.1506\n",
      "Epoch 83/100\n",
      "185/185 [==============================] - 19s 103ms/step - loss: 0.0937 - accuracy: 0.1506\n",
      "Epoch 84/100\n",
      "185/185 [==============================] - 19s 101ms/step - loss: 0.0932 - accuracy: 0.1509s - loss: 0.0932 - accuracy: 0.\n",
      "Epoch 85/100\n",
      "185/185 [==============================] - 19s 100ms/step - loss: 0.0910 - accuracy: 0.1513\n",
      "Epoch 86/100\n",
      "185/185 [==============================] - 19s 102ms/step - loss: 0.0910 - accuracy: 0.1514s - loss: - E\n",
      "Epoch 87/100\n",
      "185/185 [==============================] - 19s 105ms/step - loss: 0.0892 - accuracy: 0.1517\n",
      "Epoch 88/100\n",
      "185/185 [==============================] - 21s 113ms/step - loss: 0.0887 - accuracy: 0.1518\n",
      "Epoch 89/100\n",
      "185/185 [==============================] - 20s 109ms/step - loss: 0.0882 - accuracy: 0.1521\n",
      "Epoch 90/100\n",
      "185/185 [==============================] - 20s 111ms/step - loss: 0.0875 - accuracy: 0.1519\n",
      "Epoch 91/100\n",
      "185/185 [==============================] - 20s 109ms/step - loss: 0.0860 - accuracy: 0.1524\n",
      "Epoch 92/100\n",
      "185/185 [==============================] - 21s 113ms/step - loss: 0.0852 - accuracy: 0.1526\n",
      "Epoch 93/100\n",
      "185/185 [==============================] - 21s 114ms/step - loss: 0.0842 - accuracy: 0.1527\n",
      "Epoch 94/100\n",
      "185/185 [==============================] - 21s 115ms/step - loss: 0.0845 - accuracy: 0.1527\n",
      "Epoch 95/100\n",
      "185/185 [==============================] - 19s 105ms/step - loss: 0.0831 - accuracy: 0.1530\n",
      "Epoch 96/100\n",
      "185/185 [==============================] - 21s 112ms/step - loss: 0.0823 - accuracy: 0.1531\n",
      "Epoch 97/100\n",
      "185/185 [==============================] - 19s 101ms/step - loss: 0.0807 - accuracy: 0.1535\n",
      "Epoch 98/100\n",
      "185/185 [==============================] - 19s 105ms/step - loss: 0.0804 - accuracy: 0.1535\n",
      "Epoch 99/100\n",
      "185/185 [==============================] - 19s 104ms/step - loss: 0.0799 - accuracy: 0.1536\n",
      "Epoch 100/100\n",
      "185/185 [==============================] - 20s 108ms/step - loss: 0.0795 - accuracy: 0.1538\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "early_stop = EarlyStopping(monitor='accuracy', patience=3)\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1, callbacks=early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. 모델 평가하기\n",
    "Step 1에서 선택한 전처리 방법을 고려하여 입력된 문장에 대해서 대답을 얻는 예측 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞 뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없으므로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 너 어디있었어?\n",
      "출력 : 가게부를 써보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'가게부를 써보세요 .'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"너 어디있었어?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch 20; '저도 데려가세요 .'\n",
    "epoch 100; '오늘 헤어졌어 라고 하면 위로해 드려요 .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 넌 왜 이렇게 멍청해?\n",
      "출력 : 저는 생각보다 많이 벌어요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저는 생각보다 많이 벌어요 .'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"넌 왜 이렇게 멍청해?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch 20; '그런 사람 만나길 바랄게요 .'\n",
    "epoch 100; '저는 마음을 이어주는 위로봇입니다 .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 세상은 참 넓어.\n",
      "출력 : 성공하길 바랍니다 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'성공하길 바랍니다 .'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"세상은 참 넓어.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch 20; '서로 속도를 맞춰보세요 .'\n",
    "epoch 100; '그 말을 한 사람이 가장 이상할 거예요 .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 내 이름을 알아?\n",
      "출력 : 두통약 드세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'두통약 드세요 .'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"내 이름을 알아?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch 20; '이별이 사람을 변덕스럽게 만들더라고요 .'\n",
    "epoch 100; '재미있나봐요 .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 나 심심해.\n",
      "출력 : 친구들과 잘 어울려보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'친구들과 잘 어울려보세요 .'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"나 심심해.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 나랑 친구할래?\n",
      "출력 : 사소한 거라도 있을 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'사소한 거라도 있을 거예요 .'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"나랑 친구할래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 너는 어디에 있어?\n",
      "출력 : 벌써 그러면 안돼요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'벌써 그러면 안돼요 .'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"너는 어디에 있어?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 별들이 참 예쁘다.\n",
      "출력 : 사람을 잊는다는 건 쉬운 일이 아니니까요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'사람을 잊는다는 건 쉬운 일이 아니니까요 .'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"별들이 참 예쁘다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 사랑해.\n",
      "출력 : 억지로라도 긍정적인 감정을 끌어올려보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'억지로라도 긍정적인 감정을 끌어올려보세요 .'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"사랑해.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 외로워.\n",
      "출력 : 혼자가 아니에요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'혼자가 아니에요 .'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"외로워.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. 총평"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습과 무관하게 답변은 질문의 종류에 따라 퀄리티가 변화했다. 이는 해당 데이터의 출처로 인해 데이터의 편향성이 발생한 것이 원인으로 보인다. 또한 하이퍼 파라미터와 무관하게 accuracy는 20점 미만을 맴돌았으며 이는 모델 학습 그래프를 고려할때 모델의 깊이가 얕아서 발생하는 문제로 보인다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
