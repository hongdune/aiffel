{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Project: 멋진 챗봇 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "from konlpy.tag import Mecab\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "import random\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow import keras\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_file = pd.read_csv('/home/aiffel0042/aiffel/songys_chatbot/ChatbotData .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5285</th>\n",
       "      <td>힘내야지</td>\n",
       "      <td>응원합니다!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5286</th>\n",
       "      <td>힘든 것 좀 끝났으면</td>\n",
       "      <td>다 지나갈 거예요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5287</th>\n",
       "      <td>힘든 시기가 지나갔으면</td>\n",
       "      <td>다 지나갈 거예요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5288</th>\n",
       "      <td>힘든 데도 날 도와준 사람</td>\n",
       "      <td>잊지말고 보답하세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>힘차게 시작</td>\n",
       "      <td>응원합니다!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5290 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Q            A  label\n",
       "0              12시 땡!   하루가 또 가네요.      0\n",
       "1         1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2        3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3     3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4             PPL 심하네   눈살이 찌푸려지죠.      0\n",
       "...               ...          ...    ...\n",
       "5285             힘내야지       응원합니다!      0\n",
       "5286      힘든 것 좀 끝났으면   다 지나갈 거예요.      0\n",
       "5287     힘든 시기가 지나갔으면   다 지나갈 거예요.      0\n",
       "5288   힘든 데도 날 도와준 사람  잊지말고 보답하세요.      0\n",
       "5289           힘차게 시작       응원합니다!      0\n",
       "\n",
       "[5290 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_file[row_file['label']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5290</th>\n",
       "      <td>1000일 만난 여자친구와 이별</td>\n",
       "      <td>더 오래 만날 사람 만날 거예요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5291</th>\n",
       "      <td>10년 연애. 헤어졌습니다.</td>\n",
       "      <td>더 공허함이 크시겠네요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5292</th>\n",
       "      <td>10년 연애사 되돌아보니 다 부질없네</td>\n",
       "      <td>더 좋은 사람 만나실 거예요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5293</th>\n",
       "      <td>10년 연예의끝</td>\n",
       "      <td>더 마음이 허하겠어요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5294</th>\n",
       "      <td>10년만나다 헤어지네</td>\n",
       "      <td>충분히 슬퍼하고 충분히 아파하다가 이겨내세요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6533 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                          A  label\n",
       "5290         1000일 만난 여자친구와 이별         더 오래 만날 사람 만날 거예요.      1\n",
       "5291           10년 연애. 헤어졌습니다.              더 공허함이 크시겠네요.      1\n",
       "5292      10년 연애사 되돌아보니 다 부질없네           더 좋은 사람 만나실 거예요.      1\n",
       "5293                  10년 연예의끝               더 마음이 허하겠어요.      1\n",
       "5294               10년만나다 헤어지네  충분히 슬퍼하고 충분히 아파하다가 이겨내세요.      1\n",
       "...                        ...                        ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.         티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.              훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                     설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?   잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐         도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[6533 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_file[row_file['label']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A\n",
       "0                       12시 땡!                하루가 또 가네요.\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.\n",
       "...                        ...                       ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.\n",
       "\n",
       "[11823 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del row_file['label']\n",
    "\n",
    "row_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "  # (한글, 숫자, 영어 \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r\"[^ㄱ-ㅎ|가-힣|a-z|A-Z|0-9|?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. 데이터 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_corpus(row_file):\n",
    "    que_corpus = []\n",
    "    ans_corpus = []\n",
    "    \n",
    "    for i in range(0, len(row_file)):\n",
    "        mecab = Mecab()\n",
    "        \n",
    "        que, ans = row_file.loc[i]\n",
    "        \n",
    "        que = preprocess_sentence(que)\n",
    "        que = mecab.morphs(que)\n",
    "        \n",
    "        ans = preprocess_sentence(ans)\n",
    "        ans = mecab.morphs(ans)\n",
    "        \n",
    "        if len(que) < 20 and len(ans) < 20: #일정 길이 이상 제외\n",
    "            if que not in que_corpus:\n",
    "                if ans not in ans_corpus: #소스와 타겟별 중복 검사\n",
    "                    que_corpus.append(que)\n",
    "                    ans_corpus.append(ans)\n",
    "    \n",
    "    return que_corpus, ans_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_corpus, ans_corpus = build_corpus(row_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12', '시', '땡', '!'],\n",
       " ['1', '지망', '학교', '떨어졌', '어'],\n",
       " ['3', '박', '4', '일', '놀', '러', '가', '고', '싶', '다'],\n",
       " ['ppl', '심하', '네'],\n",
       " ['sd', '카드', '망가졌', '어'],\n",
       " ['sns', '맞', '팔', '왜', '안', '하', '지'],\n",
       " ['sns', '시간', '낭비', '인', '거', '아', '는데', '매일', '하', '는', '중'],\n",
       " ['sns', '보', '면', '나', '만', '빼', '고', '다', '행복', '해', '보여'],\n",
       " ['가끔', '궁금', '해'],\n",
       " ['가끔', '은', '혼자', '인', '게', '좋', '다']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "que_corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['하루', '가', '또', '가', '네요', '.'],\n",
       " ['위로', '해', '드립니다', '.'],\n",
       " ['여행', '은', '언제나', '좋', '죠', '.'],\n",
       " ['눈살', '이', '찌푸려', '지', '죠', '.'],\n",
       " ['다시', '새로', '사', '는', '게', '마음', '편해요', '.'],\n",
       " ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요', '.'],\n",
       " ['시간', '을', '정하', '고', '해', '보', '세요', '.'],\n",
       " ['자랑', '하', '는', '자리', '니까요', '.'],\n",
       " ['그', '사람', '도', '그럴', '거', '예요', '.'],\n",
       " ['혼자', '를', '즐기', '세요', '.']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = gensim.models.Word2Vec.load('./Downloads/ko/ko.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_sub(sentence, word2vec):\n",
    "    \n",
    "\n",
    "    res = []\n",
    "    toks = sentence\n",
    "\n",
    "    try:\n",
    "        _from = random.choice(toks)\n",
    "        _to = word2vec.most_similar(_from)[0][0]\n",
    "\n",
    "    except:   # 단어장에 없는 단어\n",
    "        return sentence\n",
    "\n",
    "    for tok in toks:\n",
    "        if tok is _from: res.append(_to)\n",
    "        else: res.append(tok)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ['12', '시', '땡', '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['12', '시', '끗', '!']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_sub(temp, word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7517\n",
      "7517\n"
     ]
    }
   ],
   "source": [
    "print(len(que_corpus))\n",
    "print(len(ans_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc94377546104a00897bc806c4933d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7517.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "src_corpus = []\n",
    "tgt_corpus = []\n",
    "\n",
    "for i in tqdm_notebook(range(len(que_corpus))):\n",
    "    que_sen = lexical_sub(que_corpus[i], word2vec)\n",
    "    ans_sen = ans_corpus[i]\n",
    "    src_corpus.append(que_sen)\n",
    "    tgt_corpus.append(ans_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350393d1f77146169d273e9b78ffd0c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7517.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(len(que_corpus))):\n",
    "    que_sen = que_corpus[i]\n",
    "    ans_sen = lexical_sub(ans_corpus[i], word2vec)\n",
    "    src_corpus.append(que_sen)\n",
    "    tgt_corpus.append(ans_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c83a72aa1a542cb8a992d7a3ac81aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7517.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(len(que_corpus))):\n",
    "    que_sen = que_corpus[i]\n",
    "    ans_sen = ans_corpus[i]\n",
    "    src_corpus.append(que_sen)\n",
    "    tgt_corpus.append(ans_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22551\n",
      "22551\n"
     ]
    }
   ],
   "source": [
    "print(len(src_corpus))\n",
    "print(len(tgt_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12', '시', '끗', '!'],\n",
       " ['1', '지망', '학교', '떨어졌', '어'],\n",
       " ['3', '박', '4', '일', '놀', 'ㄹ래', '가', '고', '싶', '다'],\n",
       " ['ppl', '강하', '네'],\n",
       " ['sd', '카드', '망가졌', '어'],\n",
       " ['sns', '맞', '나르', '왜', '안', '하', '지'],\n",
       " ['sns', '시간', '낭비', '인', '것', '아', '는데', '매일', '하', '는', '중'],\n",
       " ['sns', '보', '면', '나', '만', '빼', '고', '다', '행복', '해의', '보여'],\n",
       " ['가끔', '궁금', '해의'],\n",
       " ['가끔', '은', '혼자', '인', '게', '괜찮', '다']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_data = []\n",
    "\n",
    "for sen in tgt_corpus:\n",
    "    sen = [\"<start>\"] + sen + [\"<end>\"]\n",
    "    que_data.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<start>', '하루', '가', '또', '가', '네요', '.', '<end>'],\n",
       " ['<start>', '위로', '해', '드립니다', '.', '<end>'],\n",
       " ['<start>', '여행', '은', '언제나', '좋', '죠', '.', '<end>'],\n",
       " ['<start>', '눈살', '이', '찌푸려', '지', '죠', '.', '<end>'],\n",
       " ['<start>', '다시', '새로', '사', '는', '게', '마음', '편해요', '.', '<end>'],\n",
       " ['<start>', '잘', '모르', '고', '있', '을', '수', '도', '있', '어요', '.', '<end>'],\n",
       " ['<start>', '시간', '을', '정하', '고', '해', '보', '세요', '.', '<end>'],\n",
       " ['<start>', '자랑', '하', '는', '자리', '니까요', '.', '<end>'],\n",
       " ['<start>', '그', '사람', '도', '그럴', '거', '예요', '.', '<end>'],\n",
       " ['<start>', '혼자', '를', '즐기', '세요', '.', '<end>']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "que_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start>', '하루', '가', '또', '가', '네요', '.', '<end>']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "que_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. 데이터 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45102"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = que_data + src_corpus\n",
    "\n",
    "len(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.concatenate(total_data).tolist()\n",
    "counter = Counter(words)\n",
    "counter = counter.most_common(30000-2)\n",
    "vocab = ['<pad>', '<unk>'] + [key for key, _ in counter]\n",
    "word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '<unk>': 1,\n",
       " '.': 2,\n",
       " '<start>': 3,\n",
       " '<end>': 4,\n",
       " '이': 5,\n",
       " '는': 6,\n",
       " '하': 7,\n",
       " '을': 8,\n",
       " '가': 9,\n",
       " '세요': 10,\n",
       " '좋': 11,\n",
       " '고': 12,\n",
       " '어': 13,\n",
       " '거': 14,\n",
       " '있': 15,\n",
       " '은': 16,\n",
       " '해': 17,\n",
       " '보': 18,\n",
       " '지': 19,\n",
       " '?': 20,\n",
       " '나': 21,\n",
       " '아': 22,\n",
       " '도': 23,\n",
       " '게': 24,\n",
       " '는데': 25,\n",
       " '겠': 26,\n",
       " '에': 27,\n",
       " '사람': 28,\n",
       " '예요': 29,\n",
       " '사랑': 30,\n",
       " '어요': 31,\n",
       " '를': 32,\n",
       " '한': 33,\n",
       " '죠': 34,\n",
       " '같': 35,\n",
       " '다': 36,\n",
       " '것': 37,\n",
       " '없': 38,\n",
       " '네': 39,\n",
       " '수': 40,\n",
       " '싶': 41,\n",
       " '면': 42,\n",
       " '네요': 43,\n",
       " '의': 44,\n",
       " '안': 45,\n",
       " '친구': 46,\n",
       " '봐요': 47,\n",
       " '생각': 48,\n",
       " '않': 49,\n",
       " '마음': 50,\n",
       " '아요': 51,\n",
       " '말': 52,\n",
       " '할': 53,\n",
       " '되': 54,\n",
       " '너무': 55,\n",
       " '이별': 56,\n",
       " '했': 57,\n",
       " '잘': 58,\n",
       " '주': 59,\n",
       " '남자': 60,\n",
       " '었': 61,\n",
       " '더': 62,\n",
       " '연락': 63,\n",
       " '내': 64,\n",
       " '기': 65,\n",
       " '일': 66,\n",
       " '만': 67,\n",
       " '여자': 68,\n",
       " '들': 69,\n",
       " '힘들': 70,\n",
       " '해요': 71,\n",
       " '시간': 72,\n",
       " '남': 73,\n",
       " '썸': 74,\n",
       " '많이': 75,\n",
       " '짝': 76,\n",
       " '길': 77,\n",
       " '으로': 78,\n",
       " '한테': 79,\n",
       " '으면': 80,\n",
       " '았': 81,\n",
       " '괜찮': 82,\n",
       " '건': 83,\n",
       " '때': 84,\n",
       " '에요': 85,\n",
       " '좀': 86,\n",
       " '에서': 87,\n",
       " '요': 88,\n",
       " '에게': 89,\n",
       " '알': 90,\n",
       " '야': 91,\n",
       " '그': 92,\n",
       " '많': 93,\n",
       " '만나': 94,\n",
       " '받': 95,\n",
       " '습니다': 96,\n",
       " '로': 97,\n",
       " '저': 98,\n",
       " '던': 99,\n",
       " '그러': 100,\n",
       " '을까': 101,\n",
       " '뭐': 102,\n",
       " '먹': 103,\n",
       " '연애': 104,\n",
       " '인': 105,\n",
       " '이제': 106,\n",
       " '!': 107,\n",
       " '적': 108,\n",
       " '오늘': 109,\n",
       " '애': 110,\n",
       " '못': 111,\n",
       " '마세요': 112,\n",
       " '해도': 113,\n",
       " '자신': 114,\n",
       " '년': 115,\n",
       " '할까': 116,\n",
       " '은데': 117,\n",
       " '잊': 118,\n",
       " '아니': 119,\n",
       " '타': 120,\n",
       " '끝': 121,\n",
       " '모르': 122,\n",
       " '다시': 123,\n",
       " '필요': 124,\n",
       " '전': 125,\n",
       " '걸': 126,\n",
       " '당신': 127,\n",
       " '해야': 128,\n",
       " '다른': 129,\n",
       " '라고': 130,\n",
       " '지만': 131,\n",
       " '정말': 132,\n",
       " '어떻게': 133,\n",
       " '왜': 134,\n",
       " '또': 135,\n",
       " '정리': 136,\n",
       " '랑': 137,\n",
       " '과': 138,\n",
       " '라': 139,\n",
       " '살': 140,\n",
       " '헤어지': 141,\n",
       " '데': 142,\n",
       " '달': 143,\n",
       " '인데': 144,\n",
       " '짝사랑': 145,\n",
       " '시키': 146,\n",
       " '어서': 147,\n",
       " '결혼': 148,\n",
       " '서': 149,\n",
       " '될': 150,\n",
       " '날': 151,\n",
       " '이랑': 152,\n",
       " '방법': 153,\n",
       " '지요': 154,\n",
       " '같이': 155,\n",
       " '오': 156,\n",
       " '봐': 157,\n",
       " '제': 158,\n",
       " '그녀': 159,\n",
       " '돼': 160,\n",
       " '니': 161,\n",
       " '왔': 162,\n",
       " '참': 163,\n",
       " '중': 164,\n",
       " '아직': 165,\n",
       " '지금': 166,\n",
       " 'ㄴ다는': 167,\n",
       " '와': 168,\n",
       " '봅니다': 169,\n",
       " '후회': 170,\n",
       " '인가': 171,\n",
       " '행복': 172,\n",
       " '돼요': 173,\n",
       " '중요': 174,\n",
       " '바랄게요': 175,\n",
       " '고백': 176,\n",
       " '면서': 177,\n",
       " '꿈': 178,\n",
       " '사귀': 179,\n",
       " '준비': 180,\n",
       " '보다': 181,\n",
       " '좋아하': 182,\n",
       " '그런': 183,\n",
       " '힘든': 184,\n",
       " '혼자': 185,\n",
       " '는지': 186,\n",
       " '먼저': 187,\n",
       " '녀': 188,\n",
       " '고민': 189,\n",
       " '다면': 190,\n",
       " '싫': 191,\n",
       " '시작': 192,\n",
       " '사': 193,\n",
       " '조금': 194,\n",
       " '아서': 195,\n",
       " '때문': 196,\n",
       " '합니다': 197,\n",
       " '감정': 198,\n",
       " '힘드': 199,\n",
       " '다고': 200,\n",
       " '서로': 201,\n",
       " '선물': 202,\n",
       " '될까': 203,\n",
       " '하나': 204,\n",
       " '줄': 205,\n",
       " '가능': 206,\n",
       " '물': 207,\n",
       " '술': 208,\n",
       " '맞': 209,\n",
       " '까지': 210,\n",
       " '자': 211,\n",
       " '시': 212,\n",
       " '계속': 213,\n",
       " '번': 214,\n",
       " '만큼': 215,\n",
       " '군요': 216,\n",
       " '그럴': 217,\n",
       " '이야기': 218,\n",
       " '여친': 219,\n",
       " '헤어진지': 220,\n",
       " '두': 221,\n",
       " '기억': 222,\n",
       " '해서': 223,\n",
       " 'ㅂ시오': 224,\n",
       " '기분': 225,\n",
       " '후': 226,\n",
       " '놀드': 227,\n",
       " '진짜': 228,\n",
       " '너': 229,\n",
       " '나요': 230,\n",
       " '카톡': 231,\n",
       " '자꾸': 232,\n",
       " '걸까': 233,\n",
       " '째': 234,\n",
       " '바랍니다': 235,\n",
       " '표현': 236,\n",
       " '데이트': 237,\n",
       " '든': 238,\n",
       " '쓰': 239,\n",
       " '인지': 240,\n",
       " '집': 241,\n",
       " '라도': 242,\n",
       " '남친': 243,\n",
       " '듯': 244,\n",
       " '믿': 245,\n",
       " '쉽': 246,\n",
       " '됐': 247,\n",
       " '...': 248,\n",
       " '입니다': 249,\n",
       " '볼까': 250,\n",
       " '자고': 251,\n",
       " '미련': 252,\n",
       " '다가': 253,\n",
       " '상처': 254,\n",
       " '긴': 255,\n",
       " '어떨까': 256,\n",
       " '어도': 257,\n",
       " ',': 258,\n",
       " '걱정': 259,\n",
       " '눈': 260,\n",
       " '신경': 261,\n",
       " '니까요': 262,\n",
       " '살펴보': 263,\n",
       " '이해': 264,\n",
       " '쉬': 265,\n",
       " '이상': 266,\n",
       " '맘': 267,\n",
       " '돈': 268,\n",
       " '만들': 269,\n",
       " '하루': 270,\n",
       " '보내': 271,\n",
       " '함께': 272,\n",
       " '대화': 273,\n",
       " '썸남': 274,\n",
       " '어떤': 275,\n",
       " '해의': 276,\n",
       " '3': 277,\n",
       " '셨': 278,\n",
       " '몰라요': 279,\n",
       " '헤어졌': 280,\n",
       " '그냥': 281,\n",
       " '언제': 282,\n",
       " '무슨': 283,\n",
       " '였': 284,\n",
       " '1': 285,\n",
       " '2': 286,\n",
       " '기에': 287,\n",
       " '여행': 288,\n",
       " '함': 289,\n",
       " '누구': 290,\n",
       " '줘': 291,\n",
       " '씩': 292,\n",
       " '못하': 293,\n",
       " '된': 294,\n",
       " '새로운': 295,\n",
       " '음': 296,\n",
       " '아프': 297,\n",
       " '러': 298,\n",
       " '놀': 299,\n",
       " '관심': 300,\n",
       " '나의': 301,\n",
       " '기다리': 302,\n",
       " '이렇게': 303,\n",
       " '오래': 304,\n",
       " '어디': 305,\n",
       " '헤어진': 306,\n",
       " '결정': 307,\n",
       " '첫': 308,\n",
       " '곳': 309,\n",
       " '만날': 310,\n",
       " '어떡': 311,\n",
       " '으며': 312,\n",
       " '꼼짝': 313,\n",
       " '앞': 314,\n",
       " '속': 315,\n",
       " '이유': 316,\n",
       " '바라': 317,\n",
       " '마지막': 318,\n",
       " '머리': 319,\n",
       " '내일': 320,\n",
       " '니까': 321,\n",
       " '연인': 322,\n",
       " '이젠': 323,\n",
       " '개월': 324,\n",
       " '라는': 325,\n",
       " '공부': 326,\n",
       " '생각나': 327,\n",
       " '그렇게': 328,\n",
       " '잡': 329,\n",
       " '님': 330,\n",
       " '부담': 331,\n",
       " '선택': 332,\n",
       " '나가': 333,\n",
       " '려고': 334,\n",
       " '추억': 335,\n",
       " '잠': 336,\n",
       " '비': 337,\n",
       " '따라': 338,\n",
       " '궁금': 339,\n",
       " '텐데': 340,\n",
       " '입': 341,\n",
       " '항상': 342,\n",
       " '결국': 343,\n",
       " '똑같': 344,\n",
       " '사이': 345,\n",
       " '처럼': 346,\n",
       " '노력': 347,\n",
       " '별': 348,\n",
       " '올': 349,\n",
       " '노래': 350,\n",
       " '부터': 351,\n",
       " '뿐': 352,\n",
       " '생겼': 353,\n",
       " '을까요': 354,\n",
       " '건가': 355,\n",
       " '도록': 356,\n",
       " '도움': 357,\n",
       " '라면': 358,\n",
       " '덜': 359,\n",
       " '다는': 360,\n",
       " '변화': 361,\n",
       " '분': 362,\n",
       " '운동': 363,\n",
       " '만났': 364,\n",
       " '우리': 365,\n",
       " '정도': 366,\n",
       " '일까': 367,\n",
       " '나이': 368,\n",
       " '슬픔': 369,\n",
       " '대': 370,\n",
       " '드': 371,\n",
       " '드세요': 372,\n",
       " '직접': 373,\n",
       " '한가': 374,\n",
       " '차': 375,\n",
       " '인연': 376,\n",
       " '으니까요': 377,\n",
       " '대로': 378,\n",
       " '으세요': 379,\n",
       " '죽': 380,\n",
       " '느낌': 381,\n",
       " '전화': 382,\n",
       " '상황': 383,\n",
       " '충분히': 384,\n",
       " '꼭': 385,\n",
       " '어제': 386,\n",
       " '인생': 387,\n",
       " '질': 388,\n",
       " '그게': 389,\n",
       " '늦': 390,\n",
       " '이런': 391,\n",
       " '반': 392,\n",
       " '답답': 393,\n",
       " '자주': 394,\n",
       " '스럽': 395,\n",
       " '아침': 396,\n",
       " '순간': 397,\n",
       " '상대': 398,\n",
       " '볼': 399,\n",
       " '잘못': 400,\n",
       " '용기': 401,\n",
       " '만남': 402,\n",
       " '문제': 403,\n",
       " '는데요': 404,\n",
       " '재회': 405,\n",
       " '헤어짐': 406,\n",
       " '카나': 407,\n",
       " '관계': 408,\n",
       " '보이': 409,\n",
       " '모든': 410,\n",
       " '진심': 411,\n",
       " '이나': 412,\n",
       " '기대': 413,\n",
       " '큰': 414,\n",
       " '나쁜': 415,\n",
       " '봤': 416,\n",
       " '어야': 417,\n",
       " '세상': 418,\n",
       " '건지': 419,\n",
       " '처음': 420,\n",
       " '확인': 421,\n",
       " '매일': 422,\n",
       " '가슴': 423,\n",
       " '5': 424,\n",
       " '넘': 425,\n",
       " '감': 426,\n",
       " '붙잡': 427,\n",
       " '찾아보': 428,\n",
       " '힘': 429,\n",
       " '울': 430,\n",
       " '거나': 431,\n",
       " '현실': 432,\n",
       " '아닌': 433,\n",
       " '다가가': 434,\n",
       " '어렵': 435,\n",
       " '가지': 436,\n",
       " '밥': 437,\n",
       " '다르': 438,\n",
       " '놓': 439,\n",
       " '이에': 440,\n",
       " '의미': 441,\n",
       " '주말': 442,\n",
       " '아픔': 443,\n",
       " '짧': 444,\n",
       " '마다': 445,\n",
       " '부모': 446,\n",
       " '후폭풍': 447,\n",
       " '다음': 448,\n",
       " '모두': 449,\n",
       " '아도': 450,\n",
       " '귀찮': 451,\n",
       " '제일': 452,\n",
       " '자기': 453,\n",
       " '남편': 454,\n",
       " '까': 455,\n",
       " '듣': 456,\n",
       " '얼른': 457,\n",
       " '졌': 458,\n",
       " '둘': 459,\n",
       " '그만': 460,\n",
       " '사진': 461,\n",
       " '그렇': 462,\n",
       " '차단': 463,\n",
       " '영화': 464,\n",
       " '찾': 465,\n",
       " '없이': 466,\n",
       " '진': 467,\n",
       " '젊은이': 468,\n",
       " '몸': 469,\n",
       " '상대방': 470,\n",
       " '지내': 471,\n",
       " '글': 472,\n",
       " '받아들이': 473,\n",
       " '줬': 474,\n",
       " '건강': 475,\n",
       " '천천히': 476,\n",
       " '눈물': 477,\n",
       " '답': 478,\n",
       " '마시': 479,\n",
       " '확실': 480,\n",
       " '을지': 481,\n",
       " '티': 482,\n",
       " '버리': 483,\n",
       " '빨리': 484,\n",
       " '그래도': 485,\n",
       " '스스로': 486,\n",
       " '모습': 487,\n",
       " '별로': 488,\n",
       " '몇': 489,\n",
       " '언젠간': 490,\n",
       " '갑자기': 491,\n",
       " '가장': 492,\n",
       " '갖': 493,\n",
       " '습관': 494,\n",
       " '추천': 495,\n",
       " '행동': 496,\n",
       " '챙겨': 497,\n",
       " '아무': 498,\n",
       " '요즘': 499,\n",
       " '실수': 500,\n",
       " '복잡': 501,\n",
       " '아픈': 502,\n",
       " '났': 503,\n",
       " '갔': 504,\n",
       " '맛있': 505,\n",
       " '다니': 506,\n",
       " '대한': 507,\n",
       " '난': 508,\n",
       " '운명': 509,\n",
       " '호감': 510,\n",
       " '화': 511,\n",
       " '드릴게요': 512,\n",
       " '웃': 513,\n",
       " '잊혀': 514,\n",
       " '6': 515,\n",
       " '4': 516,\n",
       " '갈': 517,\n",
       " '익숙': 518,\n",
       " '편': 519,\n",
       " '가끔': 520,\n",
       " '밤': 521,\n",
       " '톡': 522,\n",
       " '인의': 523,\n",
       " '얼굴': 524,\n",
       " '힘내': 525,\n",
       " '란': 526,\n",
       " '나와': 527,\n",
       " '딱': 528,\n",
       " '회사': 529,\n",
       " '도와': 530,\n",
       " '은데요': 531,\n",
       " '솔직': 532,\n",
       " '만난': 533,\n",
       " '축하': 534,\n",
       " '뭘': 535,\n",
       " '극복': 536,\n",
       " '법': 537,\n",
       " '한두': 538,\n",
       " '새': 539,\n",
       " '확신': 540,\n",
       " '변하': 541,\n",
       " '그분': 542,\n",
       " '못가': 543,\n",
       " '열심히': 544,\n",
       " '날씨': 545,\n",
       " 'ㄴ다면': 546,\n",
       " '없었': 547,\n",
       " '워낙': 548,\n",
       " '약': 549,\n",
       " '쉬운': 550,\n",
       " '소개팅': 551,\n",
       " '마요': 552,\n",
       " '스트레스': 553,\n",
       " '설레': 554,\n",
       " '편지': 555,\n",
       " '뭘까': 556,\n",
       " '별후': 557,\n",
       " '자연': 558,\n",
       " '판단': 559,\n",
       " '엄청': 560,\n",
       " '형': 561,\n",
       " '차이': 562,\n",
       " '포기': 563,\n",
       " '벌써': 564,\n",
       " '바쁘': 565,\n",
       " '가능성': 566,\n",
       " '한다는': 567,\n",
       " '기다려': 568,\n",
       " '선': 569,\n",
       " '보여': 570,\n",
       " 'sns': 571,\n",
       " '아파': 572,\n",
       " '한다고': 573,\n",
       " '어때': 574,\n",
       " '낫': 575,\n",
       " '정신': 576,\n",
       " '생일': 577,\n",
       " '점점': 578,\n",
       " '동거': 579,\n",
       " '편하': 580,\n",
       " '게임': 581,\n",
       " '스러운': 582,\n",
       " '말씀': 583,\n",
       " '바람': 584,\n",
       " '할지': 585,\n",
       " '후련': 586,\n",
       " '냐': 587,\n",
       " '준': 588,\n",
       " '나오': 589,\n",
       " '무시': 590,\n",
       " '연습': 591,\n",
       " '인정': 592,\n",
       " '성공': 593,\n",
       " '알아보': 594,\n",
       " '예의': 595,\n",
       " '마주치': 596,\n",
       " '임': 597,\n",
       " '봄': 598,\n",
       " '성격': 599,\n",
       " '척': 600,\n",
       " '보통': 601,\n",
       " '세': 602,\n",
       " '관리': 603,\n",
       " '잠시': 604,\n",
       " '슬픈': 605,\n",
       " '집착': 606,\n",
       " '해질': 607,\n",
       " '짜증': 608,\n",
       " '지났': 609,\n",
       " '그리고': 610,\n",
       " '위로': 611,\n",
       " '옷': 612,\n",
       " '커피': 613,\n",
       " '학교': 614,\n",
       " '문자': 615,\n",
       " '약속': 616,\n",
       " '따뜻': 617,\n",
       " '주변': 618,\n",
       " '동안': 619,\n",
       " '아야': 620,\n",
       " '여기': 621,\n",
       " '언제나': 622,\n",
       " '가져': 623,\n",
       " '마련': 624,\n",
       " '어려워': 625,\n",
       " '카페': 626,\n",
       " '그럼': 627,\n",
       " '얘기': 628,\n",
       " '통보': 629,\n",
       " '아닌데': 630,\n",
       " '줄까': 631,\n",
       " '생활': 632,\n",
       " '거짓말': 633,\n",
       " '떠나': 634,\n",
       " '위해': 635,\n",
       " '충분': 636,\n",
       " '구': 637,\n",
       " '더니': 638,\n",
       " '무엇': 639,\n",
       " '조심': 640,\n",
       " '예쁘': 641,\n",
       " '바': 642,\n",
       " '원': 643,\n",
       " '상관': 644,\n",
       " '며': 645,\n",
       " '얼마': 646,\n",
       " '미치': 647,\n",
       " '스러워': 648,\n",
       " '핸드폰': 649,\n",
       " '과정': 650,\n",
       " '아무것': 651,\n",
       " '대해': 652,\n",
       " '일어나': 653,\n",
       " '진정': 654,\n",
       " '부분': 655,\n",
       " '우울': 656,\n",
       " '돌아오': 657,\n",
       " '맨날': 658,\n",
       " '접': 659,\n",
       " '주일': 660,\n",
       " '괴로움': 661,\n",
       " '해야지': 662,\n",
       " '소중': 663,\n",
       " '피곤': 664,\n",
       " '작': 665,\n",
       " '탈': 666,\n",
       " '지나': 667,\n",
       " '미안': 668,\n",
       " '려': 669,\n",
       " '욕': 670,\n",
       " '응원': 671,\n",
       " '잔': 672,\n",
       " '여러': 673,\n",
       " '한지': 674,\n",
       " '흐르': 675,\n",
       " '달라지': 676,\n",
       " '주기도': 677,\n",
       " '내고': 678,\n",
       " '여': 679,\n",
       " '사세요': 680,\n",
       " '옆': 681,\n",
       " '풀': 682,\n",
       " '다를': 683,\n",
       " '시켜': 684,\n",
       " '아무래도': 685,\n",
       " '존중': 686,\n",
       " '점': 687,\n",
       " '여유': 688,\n",
       " '까먹': 689,\n",
       " '어쩔': 690,\n",
       " '읽': 691,\n",
       " '못한': 692,\n",
       " '쯤': 693,\n",
       " '뭔지': 694,\n",
       " '한다면': 695,\n",
       " '만이': 696,\n",
       " '가족': 697,\n",
       " '는다면': 698,\n",
       " '깊': 699,\n",
       " '소리': 700,\n",
       " '간': 701,\n",
       " '착각': 702,\n",
       " '사친': 703,\n",
       " '부족': 704,\n",
       " '귀': 705,\n",
       " '크': 706,\n",
       " '숨': 707,\n",
       " '끊': 708,\n",
       " '이성': 709,\n",
       " '뒤': 710,\n",
       " '때때': 711,\n",
       " '곧': 712,\n",
       " '잠깐': 713,\n",
       " '허전': 714,\n",
       " '멀': 715,\n",
       " '두려워': 716,\n",
       " '그래요': 717,\n",
       " '바로': 718,\n",
       " '한데': 719,\n",
       " '엄마': 720,\n",
       " '더라고요': 721,\n",
       " '환승': 722,\n",
       " '어느덧': 723,\n",
       " '버렸': 724,\n",
       " '보냈': 725,\n",
       " '맞춰': 726,\n",
       " '자는': 727,\n",
       " '삶': 728,\n",
       " '헷갈리': 729,\n",
       " '도전': 730,\n",
       " '최고': 731,\n",
       " '재밌': 732,\n",
       " '기간': 733,\n",
       " '금방': 734,\n",
       " '원래': 735,\n",
       " '프': 736,\n",
       " '적기': 737,\n",
       " '자체': 738,\n",
       " '다행': 739,\n",
       " '바보': 740,\n",
       " '찍': 741,\n",
       " '질투': 742,\n",
       " '어느': 743,\n",
       " '본인': 744,\n",
       " '문득': 745,\n",
       " '씹': 746,\n",
       " '말로': 747,\n",
       " '어떻': 748,\n",
       " '즐거운': 749,\n",
       " '그런가': 750,\n",
       " '뭔가': 751,\n",
       " '나눠': 752,\n",
       " '밖': 753,\n",
       " '으니': 754,\n",
       " '아닌지': 755,\n",
       " '장': 756,\n",
       " '성': 757,\n",
       " '겠지': 758,\n",
       " '안녕': 759,\n",
       " '본': 760,\n",
       " '번호': 761,\n",
       " '7': 762,\n",
       " '흘렀': 763,\n",
       " '드리': 764,\n",
       " '스타일': 765,\n",
       " '종교': 766,\n",
       " '상담': 767,\n",
       " '인사': 768,\n",
       " '인기': 769,\n",
       " '엔': 770,\n",
       " '새벽': 771,\n",
       " '월과': 772,\n",
       " '매력': 773,\n",
       " '가요': 774,\n",
       " '능력': 775,\n",
       " '완전': 776,\n",
       " '재미': 777,\n",
       " '예민': 778,\n",
       " '전해': 779,\n",
       " '깨': 780,\n",
       " '일찍': 781,\n",
       " '손': 782,\n",
       " '사실': 783,\n",
       " '반복': 784,\n",
       " '흔들리': 785,\n",
       " '위한': 786,\n",
       " '타이밍': 787,\n",
       " '어려운': 788,\n",
       " '할게요': 789,\n",
       " '수록': 790,\n",
       " '주무세요': 791,\n",
       " '려면': 792,\n",
       " '서운': 793,\n",
       " '생길': 794,\n",
       " '해졌': 795,\n",
       " '알려': 796,\n",
       " '아닐까요': 797,\n",
       " '됩니다': 798,\n",
       " '인가요': 799,\n",
       " '걸로': 800,\n",
       " '경우': 801,\n",
       " '한잔': 802,\n",
       " '예쁜': 803,\n",
       " '답니다': 804,\n",
       " '적극': 805,\n",
       " '간다': 806,\n",
       " '10': 807,\n",
       " '비싸': 808,\n",
       " '분위기': 809,\n",
       " '취미': 810,\n",
       " '짐': 811,\n",
       " '잊어버리': 812,\n",
       " '자유': 813,\n",
       " '시기': 814,\n",
       " '써': 815,\n",
       " '장거리': 816,\n",
       " '답장': 817,\n",
       " '짓': 818,\n",
       " '시원': 819,\n",
       " '배우': 820,\n",
       " '배려': 821,\n",
       " '이기': 822,\n",
       " '나중': 823,\n",
       " '칭찬': 824,\n",
       " '최선': 825,\n",
       " '삭제': 826,\n",
       " '놈': 827,\n",
       " '지우': 828,\n",
       " '드디어': 829,\n",
       " '오빠': 830,\n",
       " '어쩌': 831,\n",
       " '심해': 832,\n",
       " '자리': 833,\n",
       " '돌아가': 834,\n",
       " '기회': 835,\n",
       " '그건': 836,\n",
       " '좋아할': 837,\n",
       " '멋진': 838,\n",
       " '집중': 839,\n",
       " '몰랐': 840,\n",
       " '소개': 841,\n",
       " '그대로': 842,\n",
       " '상': 843,\n",
       " '느껴': 844,\n",
       " '땐': 845,\n",
       " '8': 846,\n",
       " '자존': 847,\n",
       " '좋아해': 848,\n",
       " '괜히': 849,\n",
       " '부유층': 850,\n",
       " '갈까': 851,\n",
       " '어야지': 852,\n",
       " '야지': 853,\n",
       " '떨려': 854,\n",
       " '기본': 855,\n",
       " '현재': 856,\n",
       " '폰': 857,\n",
       " '거기': 858,\n",
       " '남의': 859,\n",
       " '당황': 860,\n",
       " '실': 861,\n",
       " '고생': 862,\n",
       " '생기': 863,\n",
       " '찾아가': 864,\n",
       " '소식': 865,\n",
       " '결심': 866,\n",
       " '불안': 867,\n",
       " '쓰이': 868,\n",
       " '휴': 869,\n",
       " '잠수': 870,\n",
       " '분간': 871,\n",
       " '이루어지': 872,\n",
       " '협조': 873,\n",
       " '대요': 874,\n",
       " '미리': 875,\n",
       " '지쳤': 876,\n",
       " '꽃': 877,\n",
       " '하늘': 878,\n",
       " '커플': 879,\n",
       " '는다는': 880,\n",
       " '더라도': 881,\n",
       " '려나': 882,\n",
       " '알바': 883,\n",
       " '나왔': 884,\n",
       " '그것': 885,\n",
       " '아무리': 886,\n",
       " '원망': 887,\n",
       " '그리워': 888,\n",
       " '때론': 889,\n",
       " '거절': 890,\n",
       " '조언': 891,\n",
       " '사귄': 892,\n",
       " '그래': 893,\n",
       " '줘야': 894,\n",
       " '캐치': 895,\n",
       " '무서워': 896,\n",
       " '시험': 897,\n",
       " '래': 898,\n",
       " '무': 899,\n",
       " '의지': 900,\n",
       " '절대': 901,\n",
       " '자책': 902,\n",
       " '위': 903,\n",
       " '느끼': 904,\n",
       " '은가': 905,\n",
       " '이거': 906,\n",
       " '밀': 907,\n",
       " '일상': 908,\n",
       " '직장': 909,\n",
       " '가사': 910,\n",
       " '놓아주': 911,\n",
       " '이루': 912,\n",
       " '존재': 913,\n",
       " '단': 914,\n",
       " '키우': 915,\n",
       " '누군가': 916,\n",
       " '경험': 917,\n",
       " '발전': 918,\n",
       " '플': 919,\n",
       " '상태': 920,\n",
       " '전환': 921,\n",
       " '싸우': 922,\n",
       " '꺼': 923,\n",
       " '비밀': 924,\n",
       " '언젠가': 925,\n",
       " '지나가': 926,\n",
       " '바뀌': 927,\n",
       " '영원': 928,\n",
       " '식': 929,\n",
       " '정말로': 930,\n",
       " '선생': 931,\n",
       " '할수록': 932,\n",
       " '피해': 933,\n",
       " '기다릴': 934,\n",
       " '누가': 935,\n",
       " '해결': 936,\n",
       " '사과': 937,\n",
       " '거리': 938,\n",
       " '냐고': 939,\n",
       " '크리스마스': 940,\n",
       " '우선': 941,\n",
       " '화장': 942,\n",
       " '힘든가': 943,\n",
       " '올려': 944,\n",
       " '될까요': 945,\n",
       " '기운': 946,\n",
       " '제대로': 947,\n",
       " '꿨': 948,\n",
       " '권태기': 949,\n",
       " '실감': 950,\n",
       " '찾아오': 951,\n",
       " '무덤덤': 952,\n",
       " '제발': 953,\n",
       " '떠난': 954,\n",
       " '끝난': 955,\n",
       " '질까': 956,\n",
       " '걔': 957,\n",
       " '한다': 958,\n",
       " '썸녀': 959,\n",
       " '됨': 960,\n",
       " '즐기': 961,\n",
       " '결과': 962,\n",
       " '꾸준히': 963,\n",
       " '군대': 964,\n",
       " '걷': 965,\n",
       " '고치': 966,\n",
       " '벌': 967,\n",
       " '높': 968,\n",
       " '생': 969,\n",
       " '말투': 970,\n",
       " '헤어': 971,\n",
       " '부탁': 972,\n",
       " '우산': 973,\n",
       " '위험': 974,\n",
       " '견디': 975,\n",
       " '헤아리': 976,\n",
       " '쓰레기': 977,\n",
       " '지켜보': 978,\n",
       " '의심': 979,\n",
       " '구불구불': 980,\n",
       " '이러': 981,\n",
       " '내리': 982,\n",
       " '방학': 983,\n",
       " '귀엽': 984,\n",
       " '책': 985,\n",
       " '기념일': 986,\n",
       " '슬프': 987,\n",
       " '끝내': 988,\n",
       " '믿음': 989,\n",
       " '도서관': 990,\n",
       " '으로서': 991,\n",
       " '명': 992,\n",
       " '가치관': 993,\n",
       " '비슷': 994,\n",
       " '완전히': 995,\n",
       " '노': 996,\n",
       " '오해': 997,\n",
       " '얼마나': 998,\n",
       " '마': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index[word] if word in word_to_index else word_to_index['<unk>'] for word in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<unk>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(corpus, word_to_index):\n",
    "    data = []\n",
    "    for sen in corpus:\n",
    "        sen = get_encoded_sentence(sen, word_to_index)\n",
    "        data.append(sen)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train = vectorize(src_corpus, word_to_index)\n",
    "dec_train = vectorize(que_data, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22551\n",
      "22551\n",
      "[2461, 212, 3722, 107]\n",
      "[3, 270, 9, 135, 9, 43, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "print(len(enc_train))\n",
    "print(len(dec_train))\n",
    "print(enc_train[0])\n",
    "print(dec_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train = keras.preprocessing.sequence.pad_sequences(enc_train,\n",
    "                                                        value=word_to_index[\"<pad>\"],\n",
    "                                                        padding='pre',\n",
    "                                                        maxlen=20)\n",
    "\n",
    "dec_train = keras.preprocessing.sequence.pad_sequences(dec_train,\n",
    "                                                       value=word_to_index[\"<pad>\"],\n",
    "                                                       padding='pre',\n",
    "                                                       maxlen=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0, 2461,  212, 3722,  107], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-1 포시셔널 인코딩 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, int(i) / d_model)\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-2 마스크 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(src_len, tgt_len):\n",
    "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_mask = generate_padding_mask(tgt)\n",
    "\n",
    "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
    "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
    "\n",
    "    dec_enc_causality_mask = generate_causality_mask(tgt.shape[1], src.shape[1])\n",
    "    dec_enc_mask = tf.maximum(enc_mask, dec_enc_causality_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-3 Multi-head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "\n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "\n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "\n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "\n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-4 Position-wise Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        self.fc1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-4 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "\n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "\n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-5 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Masked Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out, dec_enc_attn = self.dec_self_attn(out, enc_out, enc_out, causality_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "\n",
    "\n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        out = x\n",
    "\n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-6 transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared_fc=True,\n",
    "                    shared_emb=False):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        if shared_emb:\n",
    "            self.enc_emb = self.dec_emb = \\\n",
    "            tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        else:\n",
    "            self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "            self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared_fc = shared_fc\n",
    "\n",
    "        if shared_fc:\n",
    "            self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared_fc: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "\n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
    "\n",
    "        logits = self.fc(dec_out)\n",
    "\n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-7 모델 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    n_layers=2,\n",
    "    d_model=512,\n",
    "    n_heads=8,\n",
    "    d_ff=2048,\n",
    "    src_vocab_size=30000,\n",
    "    tgt_vocab_size=30000,\n",
    "    pos_len=200,\n",
    "    dropout=0.3,\n",
    "    shared_fc=True,\n",
    "    shared_emb=True)\n",
    "\n",
    "d_model = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = LearningRateScheduler(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.98, \n",
    "                                        epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    tgt_in = tgt[:, :-1]\n",
    "    gold = tgt[:, 1:]\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a439541fdd7e46d8b6b25ae772520907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=353.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143f1589127e41518953a1409ec2379d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=353.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e0c704af3f4151ad2c68690f0d1d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=353.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c711b9a18d452895b86f2997cef682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=353.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de60550335648f08dd5cda5980c2ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=353.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "\n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm_notebook(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                    dec_train[idx:idx+BATCH_SIZE],\n",
    "                    transformer,\n",
    "                    optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(corpus, word_to_index):\n",
    "    data = []\n",
    "    for sen in corpus:\n",
    "        sen = get_encoded_sentence(sen, word_to_index)\n",
    "        data.append(sen)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate()\n",
    "\n",
    "def evaluate(sentence, model):\n",
    "    mecab = Mecab()\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    pieces = mecab.morphs(sentence)\n",
    "    \n",
    "    tokens = []\n",
    "    for sen in pieces:\n",
    "        sen= get_encoded_sentence(sen, word_to_index)\n",
    "        tokens.append(sen)\n",
    "    \n",
    "    _input = keras.preprocessing.sequence.pad_sequences(tokens,\n",
    "                                                        value=word_to_index[\"<pad>\"],\n",
    "                                                        padding='pre',\n",
    "                                                        maxlen=20)\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([word_to_index[\"<start>\"]], 0)\n",
    "    for i in range(dec_train.shape[-1]):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(_input, output)\n",
    "\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
    "        model(_input, \n",
    "              output,\n",
    "              enc_padding_mask,\n",
    "              combined_mask,\n",
    "              dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if word_to_index[\"<end>\"] == predicted_id:\n",
    "            result = get_decoded_sentence(ids, index_to_word)\n",
    "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = get_decoded_sentence(ids, index_to_word)\n",
    "\n",
    "    return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "def translate(sentence, model):\n",
    "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "    evaluate(sentence, model)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sen = '지루하다, 놀러가고 싶어.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = ['지루하다, 놀러가고 싶어.',\n",
    "               '오늘 일찍 일어났더니 피곤하다.',\n",
    "               '간만에 여자친구랑 데이트 하기로 했어.',\n",
    "               '집에 있는다는 소리야.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  지루하다, 놀러가고 싶어.\n",
      "답변 :  보다 많이 생각 하 면 좋 은 생각 하 면 생각 하 면 좋 을 거 같 아요 .\n",
      "원문 :  오늘 일찍 일어났더니 피곤하다.\n",
      "답변 :  을 더 좋 은 결정 이 었 을 결정 이 안 좋 은 선택 이 었 을 텐데 .\n",
      "원문 :  간만에 여자친구랑 데이트 하기로 했어.\n",
      "답변 :  은 만남 이 안 하 게 해 는 게 서로 에게 도 안 할 수 도 있 어요 .\n",
      "원문 :  집에 있는다는 소리야.\n",
      "답변 :  좋 으면 좋 으면 좋 으면 좋 으면 좋 으면 좋 으면 좋 으면 좋 을 남겼 나요 .\n"
     ]
    }
   ],
   "source": [
    "for sen in sample_text:\n",
    "    print('원문 : ', sen)\n",
    "    print('답변 : ', translate(sen, transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8. 총평"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 transformer 모델을 사용한 프로젝트와 비교했을때 성능이 매우 나쁘다.\n",
    "이는 몇가지 측면으로 분석할 수 있는데,\n",
    "가장 주요한 사항은 데이터의 부족으로 여겨진다.\n",
    "해당 프로젝트에서 사용된 데이터 수는 약 7000여쌍이며 이와 더불어 개별 데이터가 갖고있는 정보량 역시 매우 적다.\n",
    "또한 개별 데이터가 갖고있는 정보량이 작기 때문에 희소 행렬이 발생한 것 또한 원인으로 보인다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
